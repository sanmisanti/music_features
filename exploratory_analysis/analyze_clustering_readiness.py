#!/usr/bin/env python3
"""
Script para analizar clustering readiness del dataset spotify_songs_fixed.csv

Este script evalÃºa quÃ© tan adecuado es el dataset de 18K canciones para clustering
y proporciona recomendaciones especÃ­ficas para optimizar la selecciÃ³n de 10K canciones.

Uso:
    python analyze_clustering_readiness.py
"""

import pandas as pd
import json
import os
import sys
from datetime import datetime

# AÃ±adir el directorio del proyecto al path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), '..'))

# Importar directamente sin pasar por __init__.py
import importlib.util
spec = importlib.util.spec_from_file_location(
    "clustering_readiness", 
    os.path.join(os.path.dirname(__file__), "feature_analysis", "clustering_readiness.py")
)
clustering_readiness_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(clustering_readiness_module)
ClusteringReadiness = clustering_readiness_module.ClusteringReadiness

def load_dataset():
    """Cargar el dataset spotify_songs_fixed.csv."""
    dataset_path = '../data/with_lyrics/spotify_songs_fixed.csv'
    
    if not os.path.exists(dataset_path):
        print(f"âŒ ERROR: Dataset no encontrado en {dataset_path}")
        return None
    
    try:
        # Intentar diferentes separadores
        separators = ['@@', '^', ',', ';', '\t']
        
        for sep in separators:
            try:
                print(f"ğŸ” Intentando cargar con separador '{sep}'...")
                df = pd.read_csv(dataset_path, sep=sep, encoding='utf-8', 
                               on_bad_lines='skip', low_memory=False)
                
                # Verificar que tenemos suficientes columnas y filas
                if len(df.columns) > 10 and len(df) > 1000:
                    print(f"âœ… Dataset cargado exitosamente con separador '{sep}'")
                    print(f"ğŸ“Š Dimensiones: {df.shape}")
                    print(f"ğŸ“‹ Columnas: {list(df.columns[:10])}..." if len(df.columns) > 10 else f"ğŸ“‹ Columnas: {list(df.columns)}")
                    return df
                    
            except Exception as e:
                print(f"âŒ FallÃ³ con separador '{sep}': {e}")
                continue
        
        print("âŒ ERROR: No se pudo cargar el dataset con ningÃºn separador")
        return None
        
    except Exception as e:
        print(f"âŒ ERROR cargando dataset: {e}")
        return None

def analyze_dataset_info(df):
    """Analizar informaciÃ³n bÃ¡sica del dataset."""
    print("\n" + "="*60)
    print("ğŸ“Š INFORMACIÃ“N BÃSICA DEL DATASET")
    print("="*60)
    
    print(f"ğŸ“¦ Dimensiones: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
    print(f"ğŸ’¾ Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # Identificar caracterÃ­sticas musicales disponibles
    musical_features = [
        'danceability', 'energy', 'key', 'loudness', 'mode', 
        'speechiness', 'acousticness', 'instrumentalness', 'liveness', 
        'valence', 'tempo', 'duration_ms', 'time_signature'
    ]
    
    available_features = [f for f in musical_features if f in df.columns]
    missing_features = [f for f in musical_features if f not in df.columns]
    
    print(f"\nğŸµ CARACTERÃSTICAS MUSICALES:")
    print(f"âœ… Disponibles ({len(available_features)}): {', '.join(available_features)}")
    if missing_features:
        print(f"âŒ Faltantes ({len(missing_features)}): {', '.join(missing_features)}")
    
    # Calidad de datos bÃ¡sica
    print(f"\nğŸ” CALIDAD DE DATOS:")
    total_nulls = df[available_features].isnull().sum().sum()
    print(f"ğŸ“Š Valores nulos totales: {total_nulls:,}")
    
    if total_nulls > 0:
        print("ğŸ“‹ Valores nulos por caracterÃ­stica:")
        for feature in available_features:
            nulls = df[feature].isnull().sum()
            if nulls > 0:
                print(f"   {feature}: {nulls:,} ({nulls/len(df)*100:.1f}%)")
    
    return available_features

def run_clustering_readiness_analysis(df):
    """Ejecutar anÃ¡lisis completo de clustering readiness."""
    print("\n" + "="*60)
    print("ğŸ§® ANÃLISIS DE CLUSTERING READINESS")
    print("="*60)
    
    # Inicializar analizador
    analyzer = ClusteringReadiness()
    
    # Ejecutar anÃ¡lisis completo
    print("âš™ï¸ Calculando clustering readiness score...")
    results = analyzer.calculate_clustering_readiness_score(df)
    
    if results.get('error'):
        print(f"âŒ ERROR: {results['message']}")
        return None
    
    return results

def display_results(results):
    """Mostrar resultados del anÃ¡lisis de forma organizada."""
    print(f"\nğŸ¯ CLUSTERING READINESS SCORE: {results['readiness_score']}/100")
    print(f"ğŸ“Š NIVEL: {results['readiness_level'].upper()}")
    
    # Desglose del score
    print(f"\nğŸ“‹ DESGLOSE DEL SCORE:")
    breakdown = results['score_breakdown']
    for component, score in breakdown.items():
        print(f"   {component.replace('_', ' ').title()}: {score:.1f} puntos")
    
    # AnÃ¡lisis de clustering tendency
    print(f"\nğŸ” CLUSTERING TENDENCY:")
    tendency = results['component_analysis']['clustering_tendency']
    print(f"   Hopkins Statistic: {tendency['hopkins_statistic']:.3f}")
    print(f"   InterpretaciÃ³n: {tendency['interpretation']}")
    print(f"   Confianza: {tendency['confidence_level']}")
    print(f"   TamaÃ±o muestra: {tendency['sample_size']:,}")
    
    # AnÃ¡lisis de separabilidad
    print(f"\nğŸ“ ANÃLISIS DE SEPARABILIDAD:")
    separability = results['component_analysis']['separability_analysis']
    print(f"   Score de separabilidad: {separability['separability_score']:.3f}")
    print(f"   Silhouette esperado: {separability['expected_silhouette_range']}")
    print(f"   Riesgo de overlap: {separability['overlap_risk']}")
    
    # AnÃ¡lisis de caracterÃ­sticas
    print(f"\nğŸµ ANÃLISIS DE CARACTERÃSTICAS:")
    features = results['component_analysis']['feature_analysis']
    print(f"   CaracterÃ­sticas analizadas: {features['n_features_analyzed']}")
    print(f"   Top 5 recomendadas: {', '.join(features['recommended_features'][:5])}")
    
    if features['redundant_features']:
        print(f"   CaracterÃ­sticas redundantes: {', '.join(features['redundant_features'])}")
    
    # Recomendaciones de mejora
    print(f"\nğŸ’¡ RECOMENDACIONES DE MEJORA:")
    for i, suggestion in enumerate(results['improvement_suggestions'], 1):
        print(f"   {i}. {suggestion}")

def save_results(results, df):
    """Guardar resultados en archivo JSON."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Crear directorio de resultados si no existe
    results_dir = "../outputs/clustering_readiness"
    os.makedirs(results_dir, exist_ok=True)
    
    # Preparar datos para guardar
    output_data = {
        'analysis_timestamp': timestamp,
        'dataset_info': {
            'shape': df.shape,
            'columns': list(df.columns),
            'memory_mb': df.memory_usage(deep=True).sum() / 1024**2
        },
        'clustering_readiness_results': results
    }
    
    # Guardar JSON
    output_file = f"{results_dir}/clustering_readiness_analysis_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ’¾ Resultados guardados en: {output_file}")
    return output_file

def main():
    """FunciÃ³n principal del anÃ¡lisis."""
    print("ğŸµ ANÃLISIS DE CLUSTERING READINESS - DATASET SPOTIFY SONGS")
    print("=" * 60)
    
    # 1. Cargar dataset
    print("ğŸ“‚ Cargando dataset...")
    df = load_dataset()
    if df is None:
        return
    
    # 2. InformaciÃ³n bÃ¡sica
    available_features = analyze_dataset_info(df)
    
    # 3. AnÃ¡lisis de clustering readiness
    results = run_clustering_readiness_analysis(df)
    if results is None:
        return
    
    # 4. Mostrar resultados
    display_results(results)
    
    # 5. Guardar resultados
    output_file = save_results(results, df)
    
    # 6. Resumen final
    print(f"\n" + "="*60)
    print("ğŸ“Š RESUMEN EJECUTIVO")
    print("="*60)
    
    score = results['readiness_score']
    level = results['readiness_level']
    
    if score >= 80:
        print("ğŸ† EXCELENTE: Dataset Ã³ptimo para clustering")
        print("âœ… Proceder con selecciÃ³n de 10K canciones usando criterios estÃ¡ndar")
    elif score >= 60:
        print("âœ… BUENO: Dataset adecuado para clustering con optimizaciÃ³n")
        print("ğŸ’¡ Aplicar recomendaciones antes de seleccionar 10K canciones")
    elif score >= 40:
        print("âš ï¸  ACEPTABLE: Dataset requiere mejoras significativas")
        print("ğŸ”§ Implementar feature engineering antes del clustering")
    else:
        print("âŒ PROBLEMÃTICO: Dataset inadecuado para clustering")
        print("ğŸš¨ Considerar cambiar estrategia de selecciÃ³n o algoritmo")
    
    print(f"\nğŸ“ Archivo de resultados: {output_file}")
    print("ğŸ¯ Â¡AnÃ¡lisis completado exitosamente!")

if __name__ == "__main__":
    main()