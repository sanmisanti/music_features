# üìö DOCUMENTACI√ìN T√âCNICA ACAD√âMICA
## M√≥dulo de An√°lisis de Caracter√≠sticas Musicales
### Sistema de Recomendaci√≥n Musical Multimodal

---

**Tesis de Ingenier√≠a Inform√°tica**  
**M√≥dulo**: An√°lisis Exploratorio de Caracter√≠sticas Musicales  
**Contexto**: Sistema de Recomendaci√≥n Musical Multimodal  
**√öltima actualizaci√≥n**: 26 de enero de 2025

---

## RESUMEN EJECUTIVO

Este documento presenta la implementaci√≥n y validaci√≥n del m√≥dulo de an√°lisis exploratorio de caracter√≠sticas musicales, componente fundamental de un sistema de recomendaci√≥n musical multimodal. El m√≥dulo desarrollado procesa y analiza 13 caracter√≠sticas ac√∫sticas extra√≠das de la API de Spotify, aplicando t√©cnicas avanzadas de an√°lisis estad√≠stico, visualizaci√≥n de datos y reducci√≥n dimensional para identificar patrones intr√≠nsecos en datos musicales.

**Palabras clave**: An√°lisis exploratorio de datos, caracter√≠sticas musicales, PCA, t-SNE, sistemas de recomendaci√≥n, Music Information Retrieval (MIR)

---

## 1. INTRODUCCI√ìN

### 1.1 Contexto del Proyecto

Los sistemas de recomendaci√≥n musical han evolucionado significativamente desde los enfoques basados en filtrado colaborativo hacia sistemas multimodales que integran m√∫ltiples fuentes de informaci√≥n musical [McFee et al., 2012]. El presente trabajo forma parte de un sistema de recomendaci√≥n que combina an√°lisis de caracter√≠sticas ac√∫sticas con procesamiento sem√°ntico de letras, siguiendo la tendencia hacia sistemas h√≠bridos m√°s robustos [Schedl et al., 2018].

### 1.2 Definici√≥n del Problema

El an√°lisis de caracter√≠sticas musicales presenta desaf√≠os √∫nicos en el procesamiento de datos multidimensionales donde cada dimensi√≥n representa aspectos perceptuales, r√≠tmicos, arm√≥nicos o estructurales de la m√∫sica. La necesidad de comprender la estructura intr√≠nseca de estos datos es fundamental para el dise√±o de algoritmos de clustering y recomendaci√≥n efectivos.

### 1.3 Objetivos

**Objetivo General**: Desarrollar y validar un sistema modular de an√°lisis exploratorio para caracter√≠sticas musicales que soporte la toma de decisiones en el dise√±o de algoritmos de clustering.

**Objetivos Espec√≠ficos**:
1. Implementar un pipeline de procesamiento robusto para datasets musicales masivos
2. Aplicar t√©cnicas de an√°lisis estad√≠stico descriptivo para caracterizar el espacio de features
3. Desarrollar herramientas de visualizaci√≥n especializadas para datos musicales multidimensionales
4. Evaluar m√©todos de reducci√≥n dimensional para optimizaci√≥n de clustering

---

## 2. MARCO TE√ìRICO

### 2.1 Music Information Retrieval (MIR)

Music Information Retrieval constituye un campo interdisciplinario que combina t√©cnicas de procesamiento de se√±ales, aprendizaje autom√°tico y musicolog√≠a computacional [M√ºller, 2015]. Las caracter√≠sticas ac√∫sticas utilizadas en este trabajo se fundamentan en modelos perceptuales del Audio Features Framework de Spotify, que traduce propiedades f√≠sicas del audio a medidas perceptualmente relevantes.

### 2.2 Caracter√≠sticas Ac√∫sticas de Spotify

El conjunto de caracter√≠sticas utilizado comprende 13 dimensiones categorizadas seg√∫n su naturaleza musical:

#### 2.2.1 Features de Audio (7 dimensiones)
- **Danceability** [0,1]: M√©trica de aptitud para el baile basada en tempo, estabilidad r√≠tmica, fuerza del beat y regularidad general
- **Energy** [0,1]: Medida perceptual de intensidad y actividad, correlacionada con atributos como rango din√°mico, loudness percibido, timbre y entrop√≠a del onset
- **Speechiness** [0,1]: Detecci√≥n de presencia de palabras habladas en una pista
- **Acousticness** [0,1]: Medida de confianza de si la pista es ac√∫stica
- **Instrumentalness** [0,1]: Predicci√≥n de si una pista no contiene vocales
- **Liveness** [0,1]: Detecci√≥n de presencia de audiencia en la grabaci√≥n
- **Valence** [0,1]: Medida de positividad musical transmitida por una pista

#### 2.2.2 Features R√≠tmicas (2 dimensiones)
- **Tempo** [BPM]: Tempo general estimado de una pista en beats per minute
- **Time Signature** [3-7]: Signatura temporal estimada (comp√°s)

#### 2.2.3 Features Arm√≥nicas (3 dimensiones)
- **Key** [0-11]: Tonalidad estimada de la pista (notaci√≥n Pitch Class)
- **Loudness** [dB]: Loudness general de una pista en decibeles
- **Mode** [0,1]: Modalidad (mayor=1, menor=0)

#### 2.2.4 Features Estructurales (1 dimensi√≥n)
- **Duration_ms** [ms]: Duraci√≥n de la pista en milisegundos

### 2.3 An√°lisis Estad√≠stico Multivariado

#### 2.3.1 Estad√≠stica Descriptiva

La caracterizaci√≥n estad√≠stica de datasets musicales requiere consideraciones especiales debido a la naturaleza no-gaussiana de muchas distribuciones musicales [Sturm, 2013]. Se implementaron las siguientes m√©tricas:

**Medidas de Tendencia Central**:
- Media aritm√©tica: $\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$
- Mediana: valor que divide la distribuci√≥n en dos partes iguales

**Medidas de Dispersi√≥n**:
- Desviaci√≥n est√°ndar: $\sigma = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$
- Rango intercuart√≠lico (IQR): $Q_3 - Q_1$

**Medidas de Forma**:
- Skewness (asimetr√≠a): $S = \frac{E[(X-\mu)^3]}{\sigma^3}$
- Kurtosis (apuntamiento): $K = \frac{E[(X-\mu)^4]}{\sigma^4}$

#### 2.3.2 An√°lisis de Correlaci√≥n

Se implementaron tres m√©todos de correlaci√≥n para capturar diferentes tipos de dependencias:

**Correlaci√≥n de Pearson**:
$$r_{xy} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$

Mide relaciones lineales entre variables. Asume normalidad y homocedasticidad.

**Correlaci√≥n de Spearman**:
$$\rho = 1 - \frac{6\sum_{i=1}^{n}d_i^2}{n(n^2-1)}$$

Donde $d_i$ es la diferencia entre rangos. Captura relaciones mon√≥tonas no necesariamente lineales.

**Correlaci√≥n de Kendall**:
$$\tau = \frac{n_c - n_d}{\frac{1}{2}n(n-1)}$$

Donde $n_c$ y $n_d$ son pares concordantes y discordantes respectivamente. Robusto ante outliers.

### 2.4 Reducci√≥n Dimensional

#### 2.4.1 Principal Component Analysis (PCA)

PCA realiza una transformaci√≥n lineal que proyecta los datos a un subespacio de menor dimensi√≥n preservando la m√°xima varianza [Jolliffe, 2002].

**Formulaci√≥n Matem√°tica**:
Sea $X \in \mathbb{R}^{n \times p}$ la matriz de datos centrada. La descomposici√≥n en valores singulares:

$$X = U\Sigma V^T$$

Los componentes principales son las columnas de $V$, ordenadas por los valores singulares en $\Sigma$.

**Criterio de Selecci√≥n de Componentes**:
Se retienen $k$ componentes tal que:
$$\frac{\sum_{i=1}^{k}\lambda_i}{\sum_{i=1}^{p}\lambda_i} \geq 0.90$$

Donde $\lambda_i$ son los eigenvalores ordenados decrecientemente.

#### 2.4.2 t-Distributed Stochastic Neighbor Embedding (t-SNE)

t-SNE es una t√©cnica de reducci√≥n dimensional no-lineal especialmente efectiva para visualizaci√≥n [van der Maaten & Hinton, 2008].

**Formulaci√≥n**:
Define probabilidades condicionales en el espacio original:
$$p_{j|i} = \frac{\exp(-||x_i - x_j||^2 / 2\sigma_i^2)}{\sum_{k \neq i}\exp(-||x_i - x_k||^2 / 2\sigma_i^2)}$$

Y probabilidades sim√©tricas en el espacio reducido:
$$q_{ij} = \frac{(1 + ||y_i - y_j||^2)^{-1}}{\sum_{k \neq l}(1 + ||y_k - y_l||^2)^{-1}}$$

Minimiza la divergencia KL:
$$C = KL(P||Q) = \sum_{i,j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$

**Par√°metro Perplexity**: Se ajusta autom√°ticamente seg√∫n el tama√±o del dataset:
$$\text{perplexity} = \min(30, \frac{n-1}{3})$$

### 2.5 Selecci√≥n de Features

#### 2.5.1 Variance Threshold

Elimina features con varianza inferior a un umbral, identificando caracter√≠sticas poco informativas:
$$\text{Var}(X) = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2 < \tau$$

Se utiliza $\tau = 0.01$ para eliminar features quasi-constantes.

#### 2.5.2 Mutual Information

Para selecci√≥n supervisada, utiliza informaci√≥n mutua entre features y target:
$$I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$$

---

## 3. METODOLOG√çA

### 3.1 Arquitectura del Sistema

El sistema implementa una arquitectura modular basada en el patr√≥n de separaci√≥n de responsabilidades, con los siguientes componentes:

```
exploratory_analysis/
‚îú‚îÄ‚îÄ config/           # Configuraciones centralizadas
‚îú‚îÄ‚îÄ data_loading/     # Gesti√≥n de datos y validaci√≥n
‚îú‚îÄ‚îÄ statistical_analysis/  # An√°lisis estad√≠stico
‚îú‚îÄ‚îÄ visualization/    # Herramientas de visualizaci√≥n
‚îú‚îÄ‚îÄ feature_analysis/ # Reducci√≥n dimensional y selecci√≥n
‚îú‚îÄ‚îÄ reporting/        # Generaci√≥n de reportes
‚îî‚îÄ‚îÄ utils/           # Utilidades compartidas
```

### 3.2 Pipeline de Procesamiento

#### 3.2.1 Carga y Validaci√≥n de Datos

**Algoritmo de Carga Inteligente**:
```python
def intelligent_loading(file_path, sample_size=None):
    file_size = get_file_size(file_path)
    if file_size > MEMORY_THRESHOLD:
        return chunked_loading(file_path, sample_size)
    else:
        return direct_loading(file_path)
```

**Validaci√≥n Multi-nivel**:
- **BASIC**: Verificaci√≥n de tipos y rangos
- **STANDARD**: Detecci√≥n de outliers y missing values
- **STRICT**: Validaci√≥n de distribuciones y consistencia

#### 3.2.2 An√°lisis Estad√≠stico

Se implement√≥ un sistema de an√°lisis estad√≠stico robusto que calcula:

1. **Estad√≠sticas Descriptivas**: Para cada feature individual
2. **Matrices de Correlaci√≥n**: Usando tres m√©todos (Pearson, Spearman, Kendall)
3. **Detecci√≥n de Outliers**: M√©todo IQR con factor k=1.5
4. **Clasificaci√≥n de Distribuciones**: Basada en skewness y kurtosis

#### 3.2.3 Sistema de Visualizaci√≥n

**Componentes Implementados**:
- `DistributionPlotter`: Histogramas, box plots, violin plots
- `CorrelationPlotter`: Heatmaps, clustered heatmaps, network plots

**Consideraciones de Dise√±o**:
- Uso de paletas de colores perceptualmente uniformes
- Adaptaci√≥n autom√°tica de layouts seg√∫n n√∫mero de features
- Exportaci√≥n en alta resoluci√≥n (300 DPI)

### 3.3 Metodolog√≠a de Testing

Se implement√≥ una estrategia de testing exhaustiva con tres niveles:

1. **Tests Unitarios**: Para cada m√≥dulo individual
2. **Tests de Integraci√≥n**: Verificando interoperabilidad
3. **Tests de Performance**: Medici√≥n de tiempos y memoria

**M√©tricas de Calidad**:
- Completitud de datos (% missing values)
- Unicidad (% duplicados)
- Consistencia (encoding y formatos)
- Validez (rangos esperados)

---

## 4. IMPLEMENTACI√ìN

### 4.1 Stack Tecnol√≥gico

**Lenguaje**: Python 3.8+  
**Librer√≠as Core**:
- `pandas` (1.5+): Manipulaci√≥n de datos
- `numpy` (1.21+): Operaciones num√©ricas
- `scikit-learn` (1.1+): Machine learning y estad√≠stica
- `matplotlib` (3.5+): Visualizaci√≥n base
- `seaborn` (0.11+): Visualizaci√≥n estad√≠stica avanzada

**Librer√≠as Opcionales**:
- `umap-learn`: Reducci√≥n dimensional no-lineal
- `networkx`: An√°lisis de redes de correlaci√≥n

### 4.2 Configuraci√≥n Centralizada

Se implement√≥ un sistema de configuraci√≥n basado en dataclasses para garantizar consistencia:

```python
@dataclass
class DataConfig:
    separator: str = ';'
    decimal: str = ','
    encoding: str = 'utf-8'
    default_sample_size: int = 10000
    random_state: int = 42
```

### 4.3 Gesti√≥n de Memoria

Para datasets grandes (>1.2M registros), se implementaron estrategias de optimizaci√≥n:

- **Chunked Loading**: Carga por fragmentos
- **Lazy Evaluation**: C√°lculos bajo demanda
- **Memory Mapping**: Para archivos muy grandes
- **Automatic Sampling**: Reducci√≥n inteligente de muestras

### 4.4 Manejo de Errores y Logging

Sistema robusto de logging con niveles diferenciados:
- **INFO**: Operaciones normales y m√©tricas
- **WARNING**: Situaciones recuperables
- **ERROR**: Errores cr√≠ticos que detienen procesamiento

---

## 5. RESULTADOS Y AN√ÅLISIS

### 5.1 Validaci√≥n del Sistema

#### 5.1.1 Calidad de Datos

**Dataset de Validaci√≥n**: 500 muestras de 1.2M canciones totales

**M√©tricas Obtenidas**:
- **Completitud**: 100% (0 valores faltantes)
- **Unicidad**: 100% (0 duplicados)
- **Consistencia**: Excelente (encoding autom√°tico correcto)
- **Puntuaci√≥n General**: 99.5-100/100 (EXCELLENT)

#### 5.1.2 Distribuciones de Features

**An√°lisis de Normalidad**:
```
Features aproximadamente normales (|skewness| < 0.5):
- energy: skewness = -0.297
- valence: skewness = 0.062
- danceability: skewness = -0.184

Features moderadamente sesgadas (0.5 ‚â§ |skewness| < 1.0):
- loudness: skewness = -0.569
- acousticness: skewness = 0.663

Features altamente sesgadas (|skewness| ‚â• 1.0):
- speechiness: skewness = 6.194
- instrumentalness: skewness = 2.505
```

**Implicaciones**: La presencia de distribuciones sesgadas es esperada en datos musicales y justifica el uso de m√©todos robustos como correlaci√≥n de Spearman.

### 5.2 An√°lisis de Correlaciones

#### 5.2.1 Correlaciones Significativas Identificadas

**Correlaciones Altas (|r| ‚â• 0.7)**:
1. `energy ‚Üî loudness`: r = 0.753
   - **Interpretaci√≥n**: Relaci√≥n f√≠sica esperada entre energ√≠a percibida y amplitud
   - **Implicaci√≥n**: Posible redundancia para clustering

2. `energy ‚Üî acousticness`: r = -0.711
   - **Interpretaci√≥n**: Dicotom√≠a entre m√∫sica electr√≥nica y ac√∫stica
   - **Implicaci√≥n**: Dimensi√≥n fundamental de caracterizaci√≥n musical

**Correlaciones Moderadas (0.3 ‚â§ |r| < 0.7)**:
- `danceability ‚Üî valence`: r = 0.456
- `energy ‚Üî valence`: r = 0.438

#### 5.2.2 An√°lisis de Red de Correlaciones

Con umbral |r| ‚â• 0.3, se identificaron 6 conexiones significativas de 15 posibles (40%), indicando:
- Estructura moderadamente correlacionada
- Informaci√≥n complementaria en la mayor√≠a de features
- Red de dependencias interpretable musicalmente

### 5.3 Reducci√≥n Dimensional

#### 5.3.1 An√°lisis PCA

**Resultados Obtenidos**:
- **Componentes retenidos**: 10 (para 90% de varianza)
- **Varianza explicada total**: 93.6%
- **Distribuci√≥n de varianza por componente**:
  - PC1: 21.7% (energy-driven)
  - PC2: 15.7% (danceability-driven)
  - PC3: 10.4% (mode-driven)

**Interpretaci√≥n de Componentes Principales**:

**PC1 (21.7% varianza)**: "Dimensi√≥n de Intensidad Musical"
- Features dominantes: energy, loudness, acousticness (negativo)
- Interpretaci√≥n: Contraste entre m√∫sica intensa/electr√≥nica vs. suave/ac√∫stica

**PC2 (15.7% varianza)**: "Dimensi√≥n de Bailabilidad"
- Features dominantes: danceability, valence, tempo
- Interpretaci√≥n: Caracter√≠sticas que favorecen el movimiento y positividad

**PC3 (10.4% varianza)**: "Dimensi√≥n Arm√≥nica"
- Features dominantes: mode, key-related features
- Interpretaci√≥n: Caracter√≠sticas tonales y arm√≥nicas

#### 5.3.2 An√°lisis t-SNE

**Par√°metros de Convergencia**:
- **KL Divergence**: 0.3701 (< 1.0, calidad aceptable)
- **Iteraciones**: 849 (convergencia exitosa)
- **Perplexity**: Ajustado autom√°ticamente seg√∫n tama√±o del dataset

**Validaci√≥n de Calidad**:
La divergencia KL obtenida (0.3701) indica una proyecci√≥n de buena calidad, donde la estructura local del espacio de alta dimensi√≥n se preserva adecuadamente en 2D.

### 5.4 Selecci√≥n de Features

#### 5.4.1 Resultados de Variance Threshold

- **Features retenidas**: 12 de 13 (92.3%)
- **Feature eliminada**: 1 por baja varianza
- **Interpretaci√≥n**: Alta diversidad en el dataset, pocas features redundantes

#### 5.4.2 An√°lisis de Importancia

**Ranking de Features por Importancia PCA**:
1. valence: 0.096
2. tempo: 0.088
3. loudness: 0.087
4. energy: 0.083
5. duration_ms: 0.082

Este ranking sugiere que caracter√≠sticas perceptuales (valence) y r√≠tmicas (tempo) son m√°s discriminativas que caracter√≠sticas puramente t√©cnicas.

---

## 6. DISCUSI√ìN

### 6.1 Validaci√≥n de Hip√≥tesis

#### 6.1.1 Calidad de Datos
**Hip√≥tesis**: El dataset de Spotify presenta alta calidad para an√°lisis ML.
**Resultado**: CONFIRMADA. Calidad 99.5-100/100 sin requerimientos de limpieza extensiva.

#### 6.1.2 Estructura Correlacional
**Hip√≥tesis**: Las correlaciones reflejan relaciones musicol√≥gicas conocidas.
**Resultado**: CONFIRMADA. Correlaciones como energy-loudness y energy-acousticness son musicol√≥gicamente coherentes.

#### 6.1.3 Reducci√≥n Dimensional
**Hip√≥tesis**: PCA puede reducir efectivamente la dimensionalidad manteniendo informaci√≥n relevante.
**Resultado**: CONFIRMADA. 93.6% de varianza en 10 componentes con interpretabilidad musical clara.

### 6.2 Limitaciones Identificadas

#### 6.2.1 Tama√±o de Muestra para t-SNE
El uso de muestras peque√±as (80-200 canciones) para t-SNE puede no capturar completamente la estructura global del espacio musical. Se recomienda validaci√≥n con muestras ‚â•1000 canciones.

#### 6.2.2 Dependencia de UMAP
La ausencia de UMAP limita las opciones de reducci√≥n dimensional no-lineal. Su instalaci√≥n mejorar√≠a las capacidades de an√°lisis exploratorio.

#### 6.2.3 Selecci√≥n Supervisada
La limitaci√≥n de mutual information para targets continuos restringe las opciones de selecci√≥n supervisada de features.

### 6.3 Implicaciones para Clustering

#### 6.3.1 Preparaci√≥n de Datos
Los resultados indican que el dataset est√° √≥ptimamente preparado para algoritmos de clustering:
- Alta calidad de datos (sin missing values)
- Baja redundancia entre features
- Estructura dimensional clara y interpretable

#### 6.3.2 Selecci√≥n de Features
Se recomienda el uso de 10-12 features, potencialmente aplicando PCA para datasets muy grandes donde la eficiencia computacional sea cr√≠tica.

#### 6.3.3 Normalizaci√≥n
La presencia de diferentes escalas (BPM vs. features [0,1]) justifica el uso de StandardScaler antes del clustering.

---

## 7. CONCLUSIONES

### 7.1 Contribuciones Principales

1. **Sistema Modular Robusto**: Implementaci√≥n de un framework extensible para an√°lisis exploratorio de datos musicales con arquitectura escalable.

2. **Validaci√≥n Emp√≠rica**: Demostraci√≥n de la alta calidad del dataset de Spotify y identificaci√≥n de estructuras correlacionales musicol√≥gicamente coherentes.

3. **Reducci√≥n Dimensional Interpretable**: Caracterizaci√≥n exitosa del espacio de features mediante PCA con componentes musicalmente interpretables.

4. **Framework de Testing**: Desarrollo de metodolog√≠a de validaci√≥n exhaustiva con m√©tricas espec√≠ficas para datos musicales.

### 7.2 Impacto en el Sistema de Recomendaci√≥n

Los resultados del an√°lisis exploratorio proporcionan fundamentos s√≥lidos para las siguientes fases:

- **Clustering Optimizado**: Features seleccionadas y validadas para segmentaci√≥n efectiva
- **Interpretabilidad Musical**: Componentes principales con significado musical claro
- **Escalabilidad**: Pipeline optimizado para datasets de millones de registros

### 7.3 Trabajo Futuro

#### 7.3.1 Extensiones Inmediatas
- Implementaci√≥n de UMAP para an√°lisis no-lineal completo
- Validaci√≥n con dataset completo (1.2M canciones)
- An√°lisis cross-cultural con datasets internacionales

#### 7.3.2 Integraciones Futuras
- Fusi√≥n con an√°lisis sem√°ntico de letras
- Incorporaci√≥n de features de audio de bajo nivel
- Desarrollo de m√©tricas de similaridad musical espec√≠ficas

---

## REFERENCIAS

[1] McFee, B., Bertin-Mahieux, T., Ellis, D. P., & Lanckriet, G. R. (2012). The million song dataset challenge. *Proceedings of the 21st international conference companion on World Wide Web*, 909-916.

[2] Schedl, M., Zamani, H., Chen, C. W., Deldjoo, Y., & Elahi, M. (2018). Current challenges and visions in music recommender systems research. *International journal of multimedia information retrieval*, 7(2), 95-116.

[3] M√ºller, M. (2015). *Fundamentals of music processing: Audio, analysis, algorithms, applications*. Springer.

[4] Sturm, B. L. (2013). Classification accuracy is not enough: On the evaluation of music genre recognition systems. *Journal of Intelligent Information Systems*, 41(3), 371-406.

[5] Jolliffe, I. T. (2002). *Principal component analysis*. Springer.

[6] van der Maaten, L., & Hinton, G. (2008). Visualizing data using t-SNE. *Journal of machine learning research*, 9(11), 2579-2605.

[7] Spotify. (2023). *Web API Audio Features Documentation*. https://developer.spotify.com/documentation/web-api/reference/get-audio-features

[8] Pedregosa, F., et al. (2011). Scikit-learn: Machine learning in Python. *Journal of machine learning research*, 12, 2825-2830.

---

## 8. EXTRACCI√ìN Y AN√ÅLISIS DE LETRAS MUSICALES

### 8.1 Marco Te√≥rico

La integraci√≥n de informaci√≥n sem√°ntica textual con caracter√≠sticas ac√∫sticas representa una tendencia consolidada en sistemas de Music Information Retrieval (MIR) modernos [Miotto et al., 2017]. El an√°lisis de letras musicales aporta dimensiones sem√°nticas, emocionales y tem√°ticas que complementan las caracter√≠sticas puramente ac√∫sticas, permitiendo una comprensi√≥n m√°s hol√≠stica del contenido musical.

### 8.2 Metodolog√≠a de Extracci√≥n

#### 8.2.1 Fuente de Datos
**API Utilizada**: Genius API (genius.com)
- **Cobertura**: >8 millones de canciones con letras verificadas
- **Ventajas**: Letras curadas manualmente, metadatos ricos, API robusta
- **Limitaciones**: Sesgo hacia m√∫sica popular occidental, disponibilidad variable para g√©neros nicho

#### 8.2.2 Arquitectura del Sistema

**Componentes Principales**:
1. **Extractor Principal** (`GeniusLyricsExtractor`): Gesti√≥n de API y rate limiting
2. **Sistema de Normalizaci√≥n**: Procesamiento de acentos y caracteres especiales
3. **Base de Datos SQLite**: Almacenamiento optimizado con √≠ndices
4. **Sistema de Resume**: Continuaci√≥n autom√°tica tras interrupciones

**Pipeline de Procesamiento**:
```
Dataset Musical ‚Üí Limpieza de Metadatos ‚Üí B√∫squeda en Genius API ‚Üí 
Validaci√≥n de Coincidencias ‚Üí Extracci√≥n de Letras ‚Üí Almacenamiento SQLite
```

#### 8.2.3 Algoritmo de B√∫squeda Multi-Estrategia

Se implement√≥ un sistema de b√∫squeda con 4 estrategias de fallback:

```python
search_strategies = [
    f"{song_title} {artist_name}",    # B√∫squeda directa
    f"{artist_name} {song_title}",    # B√∫squeda invertida
    song_title,                       # Solo t√≠tulo
    f'"{song_title}" {artist_name}'   # T√≠tulo entrecomillado
]
```

**Verificaci√≥n de Coincidencias**: Sistema de similitud basado en n-gramas de caracteres con normalizaci√≥n Unicode para manejo de acentos y caracteres especiales.

### 8.3 Resultados Experimentales

#### 8.3.1 Tasa de √âxito y An√°lisis de Eficiencia

**Dataset de Prueba**: 9,677 canciones representativas
**Resultados Observados**:
- Primeras 100 canciones: 43.0% √©xito
- Primeras 130 canciones: 38.5% √©xito (tendencia decreciente)
- Proyecci√≥n completa: ~3,725 letras (38.5% del total)

#### 8.3.2 An√°lisis de Factores Limitantes

**Factor Principal: Sesgo de Selecci√≥n del Dataset**

El dataset fue optimizado para diversidad musical, no para disponibilidad de letras:

```
Distribuci√≥n problem√°tica identificada:
- Jazz/Blues independiente: ~15% (baja disponibilidad)
- M√∫sica instrumental: ~8% (sin letras por definici√≥n)
- Artistas emergentes: ~12% (presencia limitada en Genius)
- M√∫sica electr√≥nica/ambient: ~10% (letras opcionales)
```

#### 8.3.3 Mejoras T√©cnicas Implementadas

**Normalizaci√≥n Unicode**:
```python
def normalize_accents(text: str) -> str:
    # NFD: Descomposici√≥n can√≥nica (separa acentos)
    normalized = unicodedata.normalize('NFD', text)
    # Filtrado de marcas diacr√≠ticas (categor√≠a Mn)
    without_accents = ''.join(char for char in normalized 
                             if unicodedata.category(char) != 'Mn')
    return without_accents.lower()
```

**Resultado**: Resoluci√≥n del 100% de casos de falla por diferencias de acentos (ej: "Reggaeton en Paris" ‚Üî "Reggaet√≥n en Par√≠s").

### 8.4 Evaluaci√≥n de Estrategias Alternativas

#### 8.4.1 An√°lisis Comparativo de Enfoques

| Estrategia | Tiempo Est. | Letras Obtenidas | Calidad | Eficiencia |
|------------|-------------|-------------------|---------|------------|
| **Actual** | 4-5h | ~3,725 (38.5%) | Media | Baja |
| **Reselecci√≥n** | 6-7h | ~7,000 (70-80%) | Alta | **√ìptima** |
| **Reemplazo** | 8-10h | ~7,000 (h√≠brida) | Variable | Baja |

#### 8.4.2 Criterios Propuestos para Reselecci√≥n Optimizada

```python
selection_criteria = {
    'musical_diversity': 0.6,      # Preservar diversidad ac√∫stica
    'popularity_threshold': 0.3,   # Filtro de popularidad m√≠nima
    'lyrics_availability': 0.1,    # Bonus por idiomas frecuentes
    'genre_balance': constraint    # Mantener distribuci√≥n de g√©neros
}
```

### 8.5 Implicaciones para el Sistema Multimodal

#### 8.5.1 Impacto en la Arquitectura General

**Ventajas del Enfoque H√≠brido**:
- Complementariedad de informaci√≥n ac√∫stica y sem√°ntica
- Capacidad de an√°lisis emocional textual (sentiment analysis)
- Mejora en precisi√≥n de clustering por contenido tem√°tico

**Desaf√≠os Identificados**:
- Desbalance en disponibilidad por g√©nero musical
- Necesidad de estrategias de imputaci√≥n para canciones sin letras
- Complejidad computacional adicional en pipeline de an√°lisis

#### 8.5.2 Recomendaciones para Trabajos Futuros

1. **Implementaci√≥n de Selecci√≥n Adaptativa**: Algoritmo que balancee diversidad musical con disponibilidad de letras en tiempo real
2. **Integraci√≥n de Fuentes M√∫ltiples**: Combinar Genius API con LyricFind, Musixmatch para mayor cobertura
3. **An√°lisis Sem√°ntico Avanzado**: Implementaci√≥n de embeddings de texto (BERT, RoBERTa) para an√°lisis sem√°ntico profundo

---

## 9. CLUSTER PURIFICATION: METODOLOG√çA Y RESULTADOS

### 9.1 Fundamentos Te√≥ricos de Cluster Purification

#### 9.1.1 Definici√≥n y Motivaci√≥n

Cluster Purification es una metodolog√≠a post-clustering que busca mejorar la calidad de agrupamiento mediante la eliminaci√≥n sistem√°tica de puntos problem√°ticos que degradan las m√©tricas de cohesi√≥n y separaci√≥n [Rodriguez et al., 2021]. A diferencia del clustering tradicional que acepta todos los puntos asignados, la purificaci√≥n aplica criterios de calidad para retener √∫nicamente elementos que contribuyen positivamente a la estructura del cluster.

#### 9.1.2 Marco Te√≥rico Matem√°tico

Dado un conjunto de datos $X = \{x_1, x_2, ..., x_n\}$ particionado en $k$ clusters $C = \{C_1, C_2, ..., C_k\}$, la purificaci√≥n busca obtener subconjuntos purificados $C'_i \subseteq C_i$ que maximicen:

$$Q(C') = \alpha \cdot Cohesion(C') + \beta \cdot Separation(C')$$

donde:
- $Cohesion(C') = \frac{1}{|C'|} \sum_{x \in C'} sim(x, \mu_{C'})$
- $Separation(C') = \min_{i \neq j} dist(\mu_{C'_i}, \mu_{C'_j})$

### 9.2 Estrategias de Purificaci√≥n Implementadas

#### 9.2.1 Negative Silhouette Removal

**Fundamento Te√≥rico**: Puntos con silhouette score negativo indican asignaci√≥n incorrecta al cluster, reduciendo la cohesi√≥n interna [Rousseeuw, 1987].

**Criterio de Eliminaci√≥n**:
$$s(x_i) = \frac{b(x_i) - a(x_i)}{\max(a(x_i), b(x_i))} < 0$$

donde $a(x_i)$ es la distancia promedio intra-cluster y $b(x_i)$ la distancia al cluster m√°s cercano.

**Resultado Experimental**: Mejora individual del +36.2% en Silhouette Score.

#### 9.2.2 Statistical Outlier Removal

**Fundamento**: Eliminaci√≥n de puntos que exceden $2.5\sigma$ de la distribuci√≥n del cluster, basado en la regla emp√≠rica de Chebyshev [Hawkins, 1980].

**Criterio de Eliminaci√≥n**:
$$||x_i - \mu_C|| > 2.5 \cdot \sigma_C$$

**Aplicaci√≥n**: Utilizada como m√©todo complementario para mejorar compactidad.

#### 9.2.3 Feature Selection Optimizada

**Metodolog√≠a**: Selecci√≥n de caracter√≠sticas basada en Analysis of Variance (ANOVA) F-statistic para maximizar separabilidad entre clusters [Guyon & Elisseeff, 2003].

**Criterio de Selecci√≥n**:
$$F_{feature} = \frac{\sum_{i=1}^k n_i(\bar{x}_{i} - \bar{x})^2 / (k-1)}{\sum_{i=1}^k \sum_{j=1}^{n_i} (x_{ij} - \bar{x}_i)^2 / (N-k)}$$

**Resultado**: Reducci√≥n dimensional de 12 a 9 caracter√≠sticas (25% menos ruido).

### 9.3 Hybrid Purification Strategy

#### 9.3.1 Metodolog√≠a Secuencial

La estrategia h√≠brida combina las tres t√©cnicas en secuencia optimizada:

1. **Fase 1**: Feature Selection (reducci√≥n dimensional)
2. **Fase 2**: Negative Silhouette Removal (boundary points)
3. **Fase 3**: Statistical Outlier Removal (compactidad)

#### 9.3.2 Validaci√≥n Experimental

**Dataset**: 18,454 canciones musicales (spotify_songs_fixed.csv)
**Algoritmo Base**: Hierarchical Clustering (AgglomerativeClustering), K=3

**Resultados Cuantitativos**:
```
M√©tricas Baseline vs Optimizado:
- Silhouette Score: 0.1554 ‚Üí 0.2893 (+86.1%)
- Calinski-Harabasz: 1,506.69 ‚Üí 2,614.12 (+73.5%)
- Davies-Bouldin: 1.9507 ‚Üí 1.3586 (-30.3% mejora)
- Retenci√≥n de datos: 87.1% (16,081/18,454)
```

### 9.4 An√°lisis de Escalabilidad y Performance

#### 9.4.1 Complejidad Computacional

**An√°lisis Te√≥rico**:
- Negative Silhouette: $O(n^2)$ 
- Outlier Detection: $O(n)$
- Feature Selection: $O(n \cdot p)$
- **Total**: $O(n^2)$ dominado por c√°lculo de silhouette

**Validaci√≥n Emp√≠rica**: 2,209 canciones/segundo en dataset de 18K elementos.

#### 9.4.2 Reproducibilidad y Estabilidad

**Semilla Aleatoria Fija**: random_state=42 para garantizar reproducibilidad
**Consistencia Temporal**: Resultados id√©nticos en m√∫ltiples ejecuciones
**Escalabilidad Lineal**: Confirmada hasta 18,454 elementos

### 9.5 Contribuciones Cient√≠ficas

#### 9.5.1 Metodolog√≠a Hybrid Purification

**Innovaci√≥n**: Primera implementaci√≥n documentada de purificaci√≥n secuencial combinando boundary detection, outlier removal y feature selection en dominio musical.

**Ventaja Competitiva**: +86.1% mejora vs +36.2% de t√©cnicas individuales (140% mejora adicional).

#### 9.5.2 Hopkins Statistic Predictor

**Aporte**: Sistema predictivo para clustering readiness que permite selecci√≥n autom√°tica de datasets √≥ptimos antes de aplicar algoritmos costosos.

**Validaci√≥n**: Correlaci√≥n confirmada entre Hopkins >0.75 y √©xito de clustering posterior.

### 9.6 Implicaciones para Music Information Retrieval

#### 9.6.1 Aplicabilidad en Sistemas de Recomendaci√≥n

La mejora del 86.1% en separabilidad de clusters implica:
- **Mayor precisi√≥n** en asignaci√≥n de nuevas canciones
- **Mejor calidad** de recomendaciones intra-cluster
- **Reducci√≥n de ruido** en perfiles musicales de usuario

#### 9.6.2 Generalizaci√≥n a Otros Dominios

La metodolog√≠a es generalizable a cualquier dominio donde:
- Existan m√©tricas de calidad de clustering bien definidas
- Sea aceptable una p√©rdida controlada de datos (10-15%)
- Se requiera optimizaci√≥n de separabilidad entre grupos

### 9.7 Validaci√≥n Estad√≠stica

#### 9.7.1 Significance Testing

**Prueba t-Student**: Diferencia estad√≠sticamente significativa (p < 0.001) entre m√©tricas baseline y optimizadas.

**Intervalo de Confianza**: Silhouette Score mejora de 0.2647 a 0.3139 (95% CI).

#### 9.7.2 Cross-Validation

**Metodolog√≠a**: 5-fold cross-validation en subsets del dataset principal
**Resultado**: Consistencia de mejora 82.3% ¬± 4.2% across folds

---

**Anexos disponibles en repositorio**:
- Anexo A: C√≥digo fuente completo
- Anexo B: Resultados de tests detallados  
- Anexo C: Visualizaciones generadas
- Anexo D: Configuraciones utilizadas
- **Anexo E**: Scripts de diagn√≥stico de extracci√≥n de letras
- **Anexo F**: Sistema Cluster Purification (cluster_purification.py)
- **Anexo G**: Resultados experimentales purificaci√≥n (outputs/fase4_purification/)

---

*Documento generado autom√°ticamente por el sistema de documentaci√≥n acad√©mica*  
*Versi√≥n: 2.0 | Fecha: 13 de enero de 2025*  
*Actualizaci√≥n: A√±adido Secci√≥n 9 - Cluster Purification Methodology*