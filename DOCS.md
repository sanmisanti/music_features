# üìö DOCUMENTACI√ìN T√âCNICA ACAD√âMICA
## M√≥dulo de An√°lisis de Caracter√≠sticas Musicales
### Sistema de Recomendaci√≥n Musical Multimodal

---

**Tesis de Ingenier√≠a Inform√°tica**  
**M√≥dulo**: An√°lisis Exploratorio de Caracter√≠sticas Musicales  
**Contexto**: Sistema de Recomendaci√≥n Musical Multimodal  
**√öltima actualizaci√≥n**: 26 de enero de 2025

---

## RESUMEN EJECUTIVO

Este documento presenta la implementaci√≥n y validaci√≥n del m√≥dulo de an√°lisis exploratorio de caracter√≠sticas musicales, componente fundamental de un sistema de recomendaci√≥n musical multimodal. El m√≥dulo desarrollado procesa y analiza 13 caracter√≠sticas ac√∫sticas extra√≠das de la API de Spotify, aplicando t√©cnicas avanzadas de an√°lisis estad√≠stico, visualizaci√≥n de datos y reducci√≥n dimensional para identificar patrones intr√≠nsecos en datos musicales.

**Palabras clave**: An√°lisis exploratorio de datos, caracter√≠sticas musicales, PCA, t-SNE, sistemas de recomendaci√≥n, Music Information Retrieval (MIR)

---

## 1. INTRODUCCI√ìN

### 1.1 Contexto del Proyecto

Los sistemas de recomendaci√≥n musical han evolucionado significativamente desde los enfoques basados en filtrado colaborativo hacia sistemas multimodales que integran m√∫ltiples fuentes de informaci√≥n musical [McFee et al., 2012]. El presente trabajo forma parte de un sistema de recomendaci√≥n que combina an√°lisis de caracter√≠sticas ac√∫sticas con procesamiento sem√°ntico de letras, siguiendo la tendencia hacia sistemas h√≠bridos m√°s robustos [Schedl et al., 2018].

### 1.2 Definici√≥n del Problema

El an√°lisis de caracter√≠sticas musicales presenta desaf√≠os √∫nicos en el procesamiento de datos multidimensionales donde cada dimensi√≥n representa aspectos perceptuales, r√≠tmicos, arm√≥nicos o estructurales de la m√∫sica. La necesidad de comprender la estructura intr√≠nseca de estos datos es fundamental para el dise√±o de algoritmos de clustering y recomendaci√≥n efectivos.

### 1.3 Objetivos

**Objetivo General**: Desarrollar y validar un sistema modular de an√°lisis exploratorio para caracter√≠sticas musicales que soporte la toma de decisiones en el dise√±o de algoritmos de clustering.

**Objetivos Espec√≠ficos**:
1. Implementar un pipeline de procesamiento robusto para datasets musicales masivos
2. Aplicar t√©cnicas de an√°lisis estad√≠stico descriptivo para caracterizar el espacio de features
3. Desarrollar herramientas de visualizaci√≥n especializadas para datos musicales multidimensionales
4. Evaluar m√©todos de reducci√≥n dimensional para optimizaci√≥n de clustering

---

## 2. MARCO TE√ìRICO

### 2.1 Music Information Retrieval (MIR)

Music Information Retrieval constituye un campo interdisciplinario que combina t√©cnicas de procesamiento de se√±ales, aprendizaje autom√°tico y musicolog√≠a computacional [M√ºller, 2015]. Las caracter√≠sticas ac√∫sticas utilizadas en este trabajo se fundamentan en modelos perceptuales del Audio Features Framework de Spotify, que traduce propiedades f√≠sicas del audio a medidas perceptualmente relevantes.

### 2.2 Caracter√≠sticas Ac√∫sticas de Spotify

El conjunto de caracter√≠sticas utilizado comprende 13 dimensiones categorizadas seg√∫n su naturaleza musical:

#### 2.2.1 Features de Audio (7 dimensiones)
- **Danceability** [0,1]: M√©trica de aptitud para el baile basada en tempo, estabilidad r√≠tmica, fuerza del beat y regularidad general
- **Energy** [0,1]: Medida perceptual de intensidad y actividad, correlacionada con atributos como rango din√°mico, loudness percibido, timbre y entrop√≠a del onset
- **Speechiness** [0,1]: Detecci√≥n de presencia de palabras habladas en una pista
- **Acousticness** [0,1]: Medida de confianza de si la pista es ac√∫stica
- **Instrumentalness** [0,1]: Predicci√≥n de si una pista no contiene vocales
- **Liveness** [0,1]: Detecci√≥n de presencia de audiencia en la grabaci√≥n
- **Valence** [0,1]: Medida de positividad musical transmitida por una pista

#### 2.2.2 Features R√≠tmicas (2 dimensiones)
- **Tempo** [BPM]: Tempo general estimado de una pista en beats per minute
- **Time Signature** [3-7]: Signatura temporal estimada (comp√°s)

#### 2.2.3 Features Arm√≥nicas (3 dimensiones)
- **Key** [0-11]: Tonalidad estimada de la pista (notaci√≥n Pitch Class)
- **Loudness** [dB]: Loudness general de una pista en decibeles
- **Mode** [0,1]: Modalidad (mayor=1, menor=0)

#### 2.2.4 Features Estructurales (1 dimensi√≥n)
- **Duration_ms** [ms]: Duraci√≥n de la pista en milisegundos

### 2.3 An√°lisis Estad√≠stico Multivariado

#### 2.3.1 Estad√≠stica Descriptiva

La caracterizaci√≥n estad√≠stica de datasets musicales requiere consideraciones especiales debido a la naturaleza no-gaussiana de muchas distribuciones musicales [Sturm, 2013]. Se implementaron las siguientes m√©tricas:

**Medidas de Tendencia Central**:
- Media aritm√©tica: $\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$
- Mediana: valor que divide la distribuci√≥n en dos partes iguales

**Medidas de Dispersi√≥n**:
- Desviaci√≥n est√°ndar: $\sigma = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2}$
- Rango intercuart√≠lico (IQR): $Q_3 - Q_1$

**Medidas de Forma**:
- Skewness (asimetr√≠a): $S = \frac{E[(X-\mu)^3]}{\sigma^3}$
- Kurtosis (apuntamiento): $K = \frac{E[(X-\mu)^4]}{\sigma^4}$

#### 2.3.2 An√°lisis de Correlaci√≥n

Se implementaron tres m√©todos de correlaci√≥n para capturar diferentes tipos de dependencias:

**Correlaci√≥n de Pearson**:
$$r_{xy} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}$$

Mide relaciones lineales entre variables. Asume normalidad y homocedasticidad.

**Correlaci√≥n de Spearman**:
$$\rho = 1 - \frac{6\sum_{i=1}^{n}d_i^2}{n(n^2-1)}$$

Donde $d_i$ es la diferencia entre rangos. Captura relaciones mon√≥tonas no necesariamente lineales.

**Correlaci√≥n de Kendall**:
$$\tau = \frac{n_c - n_d}{\frac{1}{2}n(n-1)}$$

Donde $n_c$ y $n_d$ son pares concordantes y discordantes respectivamente. Robusto ante outliers.

### 2.4 Reducci√≥n Dimensional

#### 2.4.1 Principal Component Analysis (PCA)

PCA realiza una transformaci√≥n lineal que proyecta los datos a un subespacio de menor dimensi√≥n preservando la m√°xima varianza [Jolliffe, 2002].

**Formulaci√≥n Matem√°tica**:
Sea $X \in \mathbb{R}^{n \times p}$ la matriz de datos centrada. La descomposici√≥n en valores singulares:

$$X = U\Sigma V^T$$

Los componentes principales son las columnas de $V$, ordenadas por los valores singulares en $\Sigma$.

**Criterio de Selecci√≥n de Componentes**:
Se retienen $k$ componentes tal que:
$$\frac{\sum_{i=1}^{k}\lambda_i}{\sum_{i=1}^{p}\lambda_i} \geq 0.90$$

Donde $\lambda_i$ son los eigenvalores ordenados decrecientemente.

#### 2.4.2 t-Distributed Stochastic Neighbor Embedding (t-SNE)

t-SNE es una t√©cnica de reducci√≥n dimensional no-lineal especialmente efectiva para visualizaci√≥n [van der Maaten & Hinton, 2008].

**Formulaci√≥n**:
Define probabilidades condicionales en el espacio original:
$$p_{j|i} = \frac{\exp(-||x_i - x_j||^2 / 2\sigma_i^2)}{\sum_{k \neq i}\exp(-||x_i - x_k||^2 / 2\sigma_i^2)}$$

Y probabilidades sim√©tricas en el espacio reducido:
$$q_{ij} = \frac{(1 + ||y_i - y_j||^2)^{-1}}{\sum_{k \neq l}(1 + ||y_k - y_l||^2)^{-1}}$$

Minimiza la divergencia KL:
$$C = KL(P||Q) = \sum_{i,j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$

**Par√°metro Perplexity**: Se ajusta autom√°ticamente seg√∫n el tama√±o del dataset:
$$\text{perplexity} = \min(30, \frac{n-1}{3})$$

### 2.5 Selecci√≥n de Features

#### 2.5.1 Variance Threshold

Elimina features con varianza inferior a un umbral, identificando caracter√≠sticas poco informativas:
$$\text{Var}(X) = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2 < \tau$$

Se utiliza $\tau = 0.01$ para eliminar features quasi-constantes.

#### 2.5.2 Mutual Information

Para selecci√≥n supervisada, utiliza informaci√≥n mutua entre features y target:
$$I(X;Y) = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}$$

---

## 3. METODOLOG√çA

### 3.1 Arquitectura del Sistema

El sistema implementa una arquitectura modular basada en el patr√≥n de separaci√≥n de responsabilidades, con los siguientes componentes:

```
exploratory_analysis/
‚îú‚îÄ‚îÄ config/           # Configuraciones centralizadas
‚îú‚îÄ‚îÄ data_loading/     # Gesti√≥n de datos y validaci√≥n
‚îú‚îÄ‚îÄ statistical_analysis/  # An√°lisis estad√≠stico
‚îú‚îÄ‚îÄ visualization/    # Herramientas de visualizaci√≥n
‚îú‚îÄ‚îÄ feature_analysis/ # Reducci√≥n dimensional y selecci√≥n
‚îú‚îÄ‚îÄ reporting/        # Generaci√≥n de reportes
‚îî‚îÄ‚îÄ utils/           # Utilidades compartidas
```

### 3.2 Pipeline de Procesamiento

#### 3.2.1 Carga y Validaci√≥n de Datos

**Algoritmo de Carga Inteligente**:
```python
def intelligent_loading(file_path, sample_size=None):
    file_size = get_file_size(file_path)
    if file_size > MEMORY_THRESHOLD:
        return chunked_loading(file_path, sample_size)
    else:
        return direct_loading(file_path)
```

**Validaci√≥n Multi-nivel**:
- **BASIC**: Verificaci√≥n de tipos y rangos
- **STANDARD**: Detecci√≥n de outliers y missing values
- **STRICT**: Validaci√≥n de distribuciones y consistencia

#### 3.2.2 An√°lisis Estad√≠stico

Se implement√≥ un sistema de an√°lisis estad√≠stico robusto que calcula:

1. **Estad√≠sticas Descriptivas**: Para cada feature individual
2. **Matrices de Correlaci√≥n**: Usando tres m√©todos (Pearson, Spearman, Kendall)
3. **Detecci√≥n de Outliers**: M√©todo IQR con factor k=1.5
4. **Clasificaci√≥n de Distribuciones**: Basada en skewness y kurtosis

#### 3.2.3 Sistema de Visualizaci√≥n

**Componentes Implementados**:
- `DistributionPlotter`: Histogramas, box plots, violin plots
- `CorrelationPlotter`: Heatmaps, clustered heatmaps, network plots

**Consideraciones de Dise√±o**:
- Uso de paletas de colores perceptualmente uniformes
- Adaptaci√≥n autom√°tica de layouts seg√∫n n√∫mero de features
- Exportaci√≥n en alta resoluci√≥n (300 DPI)

### 3.3 Metodolog√≠a de Testing

Se implement√≥ una estrategia de testing exhaustiva con tres niveles:

1. **Tests Unitarios**: Para cada m√≥dulo individual
2. **Tests de Integraci√≥n**: Verificando interoperabilidad
3. **Tests de Performance**: Medici√≥n de tiempos y memoria

**M√©tricas de Calidad**:
- Completitud de datos (% missing values)
- Unicidad (% duplicados)
- Consistencia (encoding y formatos)
- Validez (rangos esperados)

---

## 4. IMPLEMENTACI√ìN

### 4.1 Stack Tecnol√≥gico

**Lenguaje**: Python 3.8+  
**Librer√≠as Core**:
- `pandas` (1.5+): Manipulaci√≥n de datos
- `numpy` (1.21+): Operaciones num√©ricas
- `scikit-learn` (1.1+): Machine learning y estad√≠stica
- `matplotlib` (3.5+): Visualizaci√≥n base
- `seaborn` (0.11+): Visualizaci√≥n estad√≠stica avanzada

**Librer√≠as Opcionales**:
- `umap-learn`: Reducci√≥n dimensional no-lineal
- `networkx`: An√°lisis de redes de correlaci√≥n

### 4.2 Configuraci√≥n Centralizada

Se implement√≥ un sistema de configuraci√≥n basado en dataclasses para garantizar consistencia:

```python
@dataclass
class DataConfig:
    separator: str = ';'
    decimal: str = ','
    encoding: str = 'utf-8'
    default_sample_size: int = 10000
    random_state: int = 42
```

### 4.3 Gesti√≥n de Memoria

Para datasets grandes (>1.2M registros), se implementaron estrategias de optimizaci√≥n:

- **Chunked Loading**: Carga por fragmentos
- **Lazy Evaluation**: C√°lculos bajo demanda
- **Memory Mapping**: Para archivos muy grandes
- **Automatic Sampling**: Reducci√≥n inteligente de muestras

### 4.4 Manejo de Errores y Logging

Sistema robusto de logging con niveles diferenciados:
- **INFO**: Operaciones normales y m√©tricas
- **WARNING**: Situaciones recuperables
- **ERROR**: Errores cr√≠ticos que detienen procesamiento

---

## 5. RESULTADOS Y AN√ÅLISIS

### 5.1 Validaci√≥n del Sistema

#### 5.1.1 Calidad de Datos

**Dataset de Validaci√≥n**: 500 muestras de 1.2M canciones totales

**M√©tricas Obtenidas**:
- **Completitud**: 100% (0 valores faltantes)
- **Unicidad**: 100% (0 duplicados)
- **Consistencia**: Excelente (encoding autom√°tico correcto)
- **Puntuaci√≥n General**: 99.5-100/100 (EXCELLENT)

#### 5.1.2 Distribuciones de Features

**An√°lisis de Normalidad**:
```
Features aproximadamente normales (|skewness| < 0.5):
- energy: skewness = -0.297
- valence: skewness = 0.062
- danceability: skewness = -0.184

Features moderadamente sesgadas (0.5 ‚â§ |skewness| < 1.0):
- loudness: skewness = -0.569
- acousticness: skewness = 0.663

Features altamente sesgadas (|skewness| ‚â• 1.0):
- speechiness: skewness = 6.194
- instrumentalness: skewness = 2.505
```

**Implicaciones**: La presencia de distribuciones sesgadas es esperada en datos musicales y justifica el uso de m√©todos robustos como correlaci√≥n de Spearman.

### 5.2 An√°lisis de Correlaciones

#### 5.2.1 Correlaciones Significativas Identificadas

**Correlaciones Altas (|r| ‚â• 0.7)**:
1. `energy ‚Üî loudness`: r = 0.753
   - **Interpretaci√≥n**: Relaci√≥n f√≠sica esperada entre energ√≠a percibida y amplitud
   - **Implicaci√≥n**: Posible redundancia para clustering

2. `energy ‚Üî acousticness`: r = -0.711
   - **Interpretaci√≥n**: Dicotom√≠a entre m√∫sica electr√≥nica y ac√∫stica
   - **Implicaci√≥n**: Dimensi√≥n fundamental de caracterizaci√≥n musical

**Correlaciones Moderadas (0.3 ‚â§ |r| < 0.7)**:
- `danceability ‚Üî valence`: r = 0.456
- `energy ‚Üî valence`: r = 0.438

#### 5.2.2 An√°lisis de Red de Correlaciones

Con umbral |r| ‚â• 0.3, se identificaron 6 conexiones significativas de 15 posibles (40%), indicando:
- Estructura moderadamente correlacionada
- Informaci√≥n complementaria en la mayor√≠a de features
- Red de dependencias interpretable musicalmente

### 5.3 Reducci√≥n Dimensional

#### 5.3.1 An√°lisis PCA

**Resultados Obtenidos**:
- **Componentes retenidos**: 10 (para 90% de varianza)
- **Varianza explicada total**: 93.6%
- **Distribuci√≥n de varianza por componente**:
  - PC1: 21.7% (energy-driven)
  - PC2: 15.7% (danceability-driven)
  - PC3: 10.4% (mode-driven)

**Interpretaci√≥n de Componentes Principales**:

**PC1 (21.7% varianza)**: "Dimensi√≥n de Intensidad Musical"
- Features dominantes: energy, loudness, acousticness (negativo)
- Interpretaci√≥n: Contraste entre m√∫sica intensa/electr√≥nica vs. suave/ac√∫stica

**PC2 (15.7% varianza)**: "Dimensi√≥n de Bailabilidad"
- Features dominantes: danceability, valence, tempo
- Interpretaci√≥n: Caracter√≠sticas que favorecen el movimiento y positividad

**PC3 (10.4% varianza)**: "Dimensi√≥n Arm√≥nica"
- Features dominantes: mode, key-related features
- Interpretaci√≥n: Caracter√≠sticas tonales y arm√≥nicas

#### 5.3.2 An√°lisis t-SNE

**Par√°metros de Convergencia**:
- **KL Divergence**: 0.3701 (< 1.0, calidad aceptable)
- **Iteraciones**: 849 (convergencia exitosa)
- **Perplexity**: Ajustado autom√°ticamente seg√∫n tama√±o del dataset

**Validaci√≥n de Calidad**:
La divergencia KL obtenida (0.3701) indica una proyecci√≥n de buena calidad, donde la estructura local del espacio de alta dimensi√≥n se preserva adecuadamente en 2D.

### 5.4 Selecci√≥n de Features

#### 5.4.1 Resultados de Variance Threshold

- **Features retenidas**: 12 de 13 (92.3%)
- **Feature eliminada**: 1 por baja varianza
- **Interpretaci√≥n**: Alta diversidad en el dataset, pocas features redundantes

#### 5.4.2 An√°lisis de Importancia

**Ranking de Features por Importancia PCA**:
1. valence: 0.096
2. tempo: 0.088
3. loudness: 0.087
4. energy: 0.083
5. duration_ms: 0.082

Este ranking sugiere que caracter√≠sticas perceptuales (valence) y r√≠tmicas (tempo) son m√°s discriminativas que caracter√≠sticas puramente t√©cnicas.

---

## 6. DISCUSI√ìN

### 6.1 Validaci√≥n de Hip√≥tesis

#### 6.1.1 Calidad de Datos
**Hip√≥tesis**: El dataset de Spotify presenta alta calidad para an√°lisis ML.
**Resultado**: CONFIRMADA. Calidad 99.5-100/100 sin requerimientos de limpieza extensiva.

#### 6.1.2 Estructura Correlacional
**Hip√≥tesis**: Las correlaciones reflejan relaciones musicol√≥gicas conocidas.
**Resultado**: CONFIRMADA. Correlaciones como energy-loudness y energy-acousticness son musicol√≥gicamente coherentes.

#### 6.1.3 Reducci√≥n Dimensional
**Hip√≥tesis**: PCA puede reducir efectivamente la dimensionalidad manteniendo informaci√≥n relevante.
**Resultado**: CONFIRMADA. 93.6% de varianza en 10 componentes con interpretabilidad musical clara.

### 6.2 Limitaciones Identificadas

#### 6.2.1 Tama√±o de Muestra para t-SNE
El uso de muestras peque√±as (80-200 canciones) para t-SNE puede no capturar completamente la estructura global del espacio musical. Se recomienda validaci√≥n con muestras ‚â•1000 canciones.

#### 6.2.2 Dependencia de UMAP
La ausencia de UMAP limita las opciones de reducci√≥n dimensional no-lineal. Su instalaci√≥n mejorar√≠a las capacidades de an√°lisis exploratorio.

#### 6.2.3 Selecci√≥n Supervisada
La limitaci√≥n de mutual information para targets continuos restringe las opciones de selecci√≥n supervisada de features.

### 6.3 Implicaciones para Clustering

#### 6.3.1 Preparaci√≥n de Datos
Los resultados indican que el dataset est√° √≥ptimamente preparado para algoritmos de clustering:
- Alta calidad de datos (sin missing values)
- Baja redundancia entre features
- Estructura dimensional clara y interpretable

#### 6.3.2 Selecci√≥n de Features
Se recomienda el uso de 10-12 features, potencialmente aplicando PCA para datasets muy grandes donde la eficiencia computacional sea cr√≠tica.

#### 6.3.3 Normalizaci√≥n
La presencia de diferentes escalas (BPM vs. features [0,1]) justifica el uso de StandardScaler antes del clustering.

---

## 7. CONCLUSIONES

### 7.1 Contribuciones Principales

1. **Sistema Modular Robusto**: Implementaci√≥n de un framework extensible para an√°lisis exploratorio de datos musicales con arquitectura escalable.

2. **Validaci√≥n Emp√≠rica**: Demostraci√≥n de la alta calidad del dataset de Spotify y identificaci√≥n de estructuras correlacionales musicol√≥gicamente coherentes.

3. **Reducci√≥n Dimensional Interpretable**: Caracterizaci√≥n exitosa del espacio de features mediante PCA con componentes musicalmente interpretables.

4. **Framework de Testing**: Desarrollo de metodolog√≠a de validaci√≥n exhaustiva con m√©tricas espec√≠ficas para datos musicales.

### 7.2 Impacto en el Sistema de Recomendaci√≥n

Los resultados del an√°lisis exploratorio proporcionan fundamentos s√≥lidos para las siguientes fases:

- **Clustering Optimizado**: Features seleccionadas y validadas para segmentaci√≥n efectiva
- **Interpretabilidad Musical**: Componentes principales con significado musical claro
- **Escalabilidad**: Pipeline optimizado para datasets de millones de registros

### 7.3 Trabajo Futuro

#### 7.3.1 Extensiones Inmediatas
- Implementaci√≥n de UMAP para an√°lisis no-lineal completo
- Validaci√≥n con dataset completo (1.2M canciones)
- An√°lisis cross-cultural con datasets internacionales

#### 7.3.2 Integraciones Futuras
- Fusi√≥n con an√°lisis sem√°ntico de letras
- Incorporaci√≥n de features de audio de bajo nivel
- Desarrollo de m√©tricas de similaridad musical espec√≠ficas

---

## REFERENCIAS

[1] McFee, B., Bertin-Mahieux, T., Ellis, D. P., & Lanckriet, G. R. (2012). The million song dataset challenge. *Proceedings of the 21st international conference companion on World Wide Web*, 909-916.

[2] Schedl, M., Zamani, H., Chen, C. W., Deldjoo, Y., & Elahi, M. (2018). Current challenges and visions in music recommender systems research. *International journal of multimedia information retrieval*, 7(2), 95-116.

[3] M√ºller, M. (2015). *Fundamentals of music processing: Audio, analysis, algorithms, applications*. Springer.

[4] Sturm, B. L. (2013). Classification accuracy is not enough: On the evaluation of music genre recognition systems. *Journal of Intelligent Information Systems*, 41(3), 371-406.

[5] Jolliffe, I. T. (2002). *Principal component analysis*. Springer.

[6] van der Maaten, L., & Hinton, G. (2008). Visualizing data using t-SNE. *Journal of machine learning research*, 9(11), 2579-2605.

[7] Spotify. (2023). *Web API Audio Features Documentation*. https://developer.spotify.com/documentation/web-api/reference/get-audio-features

[8] Pedregosa, F., et al. (2011). Scikit-learn: Machine learning in Python. *Journal of machine learning research*, 12, 2825-2830.

---

**Anexos disponibles en repositorio**:
- Anexo A: C√≥digo fuente completo
- Anexo B: Resultados de tests detallados
- Anexo C: Visualizaciones generadas
- Anexo D: Configuraciones utilizadas

---

*Documento generado autom√°ticamente por el sistema de documentaci√≥n acad√©mica*  
*Versi√≥n: 1.0 | Fecha: 26 de enero de 2025*