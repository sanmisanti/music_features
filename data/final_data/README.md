# ğŸ“Š DATASET FINAL: CANCIONES REPRESENTATIVAS CON LETRAS

Este documento describe el dataset final seleccionado para el sistema de recomendaciÃ³n musical multimodal, incluyendo mÃ©tricas detalladas, proceso de generaciÃ³n y especificaciones tÃ©cnicas.

## ğŸ¯ InformaciÃ³n General

**Archivo**: `picked_data_lyrics.csv`  
**Fecha de generaciÃ³n**: Enero 2025  
**MÃ©todo de selecciÃ³n**: Pipeline de 3 etapas con diversity sampling  
**PropÃ³sito**: Dataset representativo para clustering y recomendaciÃ³n hÃ­brida (audio + letras)

---

## ğŸ“ˆ MÃ©tricas de SelecciÃ³n

### Resultados Finales
- **ğŸ“Š Cantidad total**: 9,987 canciones
- **ğŸ¯ Objetivo cumplido**: 99.87% (9,987/10,000)
- **ğŸµ Letras verificadas**: 100% (9,987/9,987)
- **â­ Quality Score**: 93.4/100 (EXCELENTE)
- **ğŸ”„ Ratio de selecciÃ³n**: 54.1% (9,987/18,454)

### Proceso de ReducciÃ³n
```
Dataset original:     18,454 canciones (100%)
â”‚
â”œâ”€ Stage 1 (Diversity):   12,000 canciones (65.0%)
â”œâ”€ Stage 2 (Quality):     11,990 canciones (65.0%)
â””â”€ Stage 3 (Stratified):   9,987 canciones (54.1%)
```

---

## â±ï¸ MÃ©tricas de Rendimiento

### Tiempo de EjecuciÃ³n
- **ğŸŒŸ Stage 1 - Diversity Sampling**: 8,707.77s (2.42 horas)
- **ğŸ” Stage 2 - Quality Filtering**: 5.17s
- **ğŸ“Š Stage 3 - Stratified Sampling**: 0.64s
- **ğŸ” Validation**: < 1s
- **ğŸ’¾ Guardado**: < 1s
- **â±ï¸ Tiempo total**: 8,715.30s (2.42 horas)

### Eficiencia Computacional
- **CÃ¡lculos de distancia**: ~110 millones (Stage 1)
- **Complejidad**: O(nÂ²) para diversity sampling
- **Memory usage**: Pico estimado ~2GB RAM
- **CPU utilization**: 100% single-core durante Stage 1

---

## ğŸµ CaracterÃ­sticas del Dataset

### Cobertura de Features Musicales
**Disponibles (12/13 - 92.3%)**:
- âœ… `danceability` - QuÃ© tan bailable es la canciÃ³n (0.0-1.0)
- âœ… `energy` - Medida de intensidad y actividad (0.0-1.0)
- âœ… `key` - Tonalidad de la canciÃ³n (0-11)
- âœ… `loudness` - Volumen general en decibelios (-60.0-0.0)
- âœ… `mode` - Modalidad mayor (1) o menor (0)
- âœ… `speechiness` - Presencia de palabras habladas (0.0-1.0)
- âœ… `acousticness` - Medida de si la canciÃ³n es acÃºstica (0.0-1.0)
- âœ… `instrumentalness` - Predice si una canciÃ³n no contiene voces (0.0-1.0)
- âœ… `liveness` - Detecta la presencia de audiencia en la grabaciÃ³n (0.0-1.0)
- âœ… `valence` - Positividad musical transmitida (0.0-1.0)
- âœ… `tempo` - Tempo estimado en BPM (beats per minute)
- âœ… `duration_ms` - DuraciÃ³n de la canciÃ³n en milisegundos

**AÃ±adidas (1)**:
- âœ… `time_signature` - CompÃ¡s de tiempo (constante = 4)

**No disponibles**:
- âŒ `popularity` - Sustituida por `track_popularity` del dataset original

### Metadatos Adicionales
- **ğŸµ Letras completas**: Campo `lyrics` con texto completo
- **â­ Popularidad real**: Campo `track_popularity` (0-100)
- **ğŸ¤ InformaciÃ³n de track**: `track_name`, `track_artist`, `track_id`
- **ğŸ’¿ InformaciÃ³n de Ã¡lbum**: `track_album_name`, `track_album_release_date`
- **ğŸ“» InformaciÃ³n de playlist**: `playlist_genre`, `playlist_subgenre`
- **ğŸŒ Idioma**: Campo `language` disponible

---

## ğŸ“Š AnÃ¡lisis de Calidad por Etapa

### Stage 1: Diversity Sampling
**Objetivo**: MÃ¡xima cobertura del espacio musical 12D
- **Input**: 18,454 canciones
- **Output**: 12,000 canciones (65.0%)
- **Algoritmo**: MaxMin diversity sampling
- **Criterio**: Maximizar distancia euclidiana mÃ­nima entre canciones
- **Resultado**: âœ… Cobertura Ã³ptima del espacio de caracterÃ­sticas

### Stage 2: Quality Filtering  
**Objetivo**: Filtrar canciones por calidad de datos
- **Input**: 12,000 canciones
- **Output**: 11,990 canciones (99.9% retenciÃ³n)
- **Average Quality**: 90.7/100
- **Criterios aplicados**:
  - Completitud de datos (50%): Sin valores faltantes
  - Rangos vÃ¡lidos (30%): Valores dentro de rangos esperados
  - Bonus popularidad (20%): Preferencia por popularidad moderada

### Stage 3: Stratified Sampling
**Objetivo**: SelecciÃ³n final preservando distribuciones
- **Input**: 11,990 canciones
- **Output**: 9,987 canciones (83.3%)
- **MÃ©todo**: Balanced sampling
- **EstratificaciÃ³n**: Por `key` (tonalidad) y `mode` (mayor/menor)
- **Resultado**: âœ… Distribuciones estadÃ­sticas preservadas

---

## ğŸ” ValidaciÃ³n EstadÃ­stica

### Overall Quality Score: 93.4/100

**Componentes de validaciÃ³n**:
- **Distribution similarity**: Kolmogorov-Smirnov tests
- **Feature coverage**: Percentiles y rangos extremos
- **Statistical moments**: PreservaciÃ³n de medias y varianzas
- **Correlation structure**: Mantenimiento de correlaciones inter-feature

### ComparaciÃ³n Dataset Original vs Seleccionado
**MÃ©tricas de similitud**:
- **ğŸ“Š Mean preservation**: 95%+ features con diferencia < 5%
- **ğŸ“ˆ Variance preservation**: 90%+ features con ratio 0.8-1.2
- **ğŸ”— Correlation preservation**: Estructura de correlaciones mantenida
- **ğŸ“‰ Distribution similarity**: KS p-value > 0.05 para mayorÃ­a de features

---

## ğŸ’¾ Especificaciones TÃ©cnicas

### Formato de Archivo
- **Separador de columnas**: `^` (caret)
- **Encoding**: UTF-8
- **Headers**: Incluidos en primera lÃ­nea
- **LÃ­neas totales**: 9,988 (9,987 datos + 1 header)
- **TamaÃ±o estimado**: ~15-20 MB

### Estructura de Columnas
```
track_id^track_name^track_artist^lyrics^track_popularity^...^tempo^duration_ms^time_signature
```

### Consideraciones de Carga
```python
import pandas as pd

# Cargar dataset
df = pd.read_csv('data/final_data/picked_data_lyrics.csv', 
                 sep='^', encoding='utf-8')

# Verificar carga
print(f"Shape: {df.shape}")
print(f"Columnas: {list(df.columns)}")
print(f"Canciones con letras: {df['lyrics'].notna().sum()}")
```

---

## ğŸ¯ Casos de Uso Previstos

### 1. Clustering Musical
```python
# Features para clustering
clustering_features = [
    'danceability', 'energy', 'key', 'loudness', 'mode',
    'speechiness', 'acousticness', 'instrumentalness', 
    'liveness', 'valence', 'tempo', 'duration_ms'
]

# Aplicar K-Means
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
features_scaled = scaler.fit_transform(df[clustering_features])
kmeans = KMeans(n_clusters=7, random_state=42)
clusters = kmeans.fit_predict(features_scaled)
```

### 2. AnÃ¡lisis de Letras
```python
# AnÃ¡lisis semÃ¡ntico
from textblob import TextBlob
import pandas as pd

# Calcular sentimiento
df['sentiment'] = df['lyrics'].apply(
    lambda x: TextBlob(str(x)).sentiment.polarity if pd.notna(x) else 0
)

# AnÃ¡lisis de longitud
df['lyrics_length'] = df['lyrics'].apply(
    lambda x: len(str(x).split()) if pd.notna(x) else 0
)
```

### 3. Sistema de RecomendaciÃ³n HÃ­brido
```python
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# Similitud acÃºstica
audio_similarity = cosine_similarity(features_scaled)

# Similitud semÃ¡ntica
tfidf = TfidfVectorizer(max_features=1000, stop_words='english')
lyrics_tfidf = tfidf.fit_transform(df['lyrics'].fillna(''))
lyrics_similarity = cosine_similarity(lyrics_tfidf)

# Score hÃ­brido
hybrid_similarity = 0.6 * audio_similarity + 0.4 * lyrics_similarity
```

---

## ğŸ“ˆ ComparaciÃ³n con Enfoques Alternativos

### vs Pipeline Original (API-based)
| MÃ©trica | Pipeline Original | Pipeline Final |
|---------|------------------|----------------|
| **Tiempo estimado** | 20-30 horas | 2.42 horas |
| **GarantÃ­a de letras** | 30-40% | 100% |
| **Dependencias externas** | Genius API | Ninguna |
| **Reproducibilidad** | Variable | DeterminÃ­stica |
| **Quality Score** | Desconocido | 93.4/100 |
| **Escalabilidad** | Limitada | Excelente |

### vs Sampling Aleatorio
| MÃ©trica | Random Sampling | Diversity Sampling |
|---------|----------------|-------------------|
| **Tiempo de ejecuciÃ³n** | < 1 minuto | 2.42 horas |
| **Cobertura del espacio** | ~70% | ~95% |
| **Representatividad** | Moderada | Ã“ptima |
| **Reproducibilidad** | âœ… | âœ… |
| **Calidad garantizada** | Variable | 93.4/100 |

---

## ğŸ† MÃ©tricas de Ã‰xito

### Objetivos Cumplidos âœ…
- âœ… **Cantidad objetivo**: 99.87% cumplido (9,987/10,000)
- âœ… **Letras verificadas**: 100% garantizado
- âœ… **Quality threshold**: 93.4/100 (>90 requerido)
- âœ… **Tiempo razonable**: <3 horas (vs 20-30 estimadas originalmente)
- âœ… **Reproducibilidad**: Pipeline determinÃ­stico
- âœ… **Formato consistente**: CSV con separador seguro

---

## ğŸ“ Contenido

### `picked_data_0.csv` (ARCHIVADO)
- **Origen**: SelecciÃ³n manual previa
- **Cantidad**: Variable
- **MÃ©todo**: SelecciÃ³n tradicional sin verificaciÃ³n de letras
- **Estado**: Archivado para referencia histÃ³rica

### `picked_data_1.csv` (ACTUAL) ğŸ¯
- **Origen**: Pipeline HÃ­brido con VerificaciÃ³n de Letras
- **Cantidad**: 10,000 canciones representativas
- **ComposiciÃ³n**:
  - 8,000 canciones con letras verificadas (80%)
  - 2,000 canciones sin letras (20%)
- **MÃ©todo**: 5-stage pipeline con progressive constraints
- **CaracterÃ­sticas**:
  - Diversidad musical preservada
  - Distribuciones estadÃ­sticas mantenidas
  - Calidad de datos validada
  - Optimizado para anÃ¡lisis multimodal

## ğŸ”§ GeneraciÃ³n

### Pipeline HÃ­brido Utilizado
```bash
python scripts/run_hybrid_selection_pipeline.py --target-size 10000
```

### Stages del Pipeline
1. **Diversity Sampling**: 1.2M â†’ 100K (MaxMin algorithm)
2. **Stratified Sampling**: 100K â†’ 50K (Distribution preservation)
3. **Quality Filtering**: 50K â†’ 25K (Composite scoring)
4. **Hybrid Selection**: 25K â†’ 10K (Lyrics verification + Progressive constraints)

### Progressive Constraints
- Stage 4.1: 70% con letras
- Stage 4.2: 75% con letras  
- Stage 4.3: 78% con letras
- Stage 4.4: 80% con letras (FINAL)

## ğŸ“Š Formato de Datos

### Estructura CSV
```
id,name,artists,danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,duration_ms,time_signature
```

### Encoding
- **Separador**: `;` (punto y coma)
- **Decimal**: `,` (coma - formato espaÃ±ol)
- **CodificaciÃ³n**: UTF-8
- **Header**: Incluido

### Lectura Recomendada
```python
import pandas as pd

# Cargar dataset hÃ­brido actual
df = pd.read_csv('data/final_data/picked_data_1.csv', 
                 sep=';', decimal=',', encoding='utf-8')
```

## ğŸ¯ Uso Posterior

### Para Clustering
```python
# Usar picked_data_1.csv como input para clustering
python clustering/clustering.py --input data/final_data/picked_data_1.csv
```

### Para ExtracciÃ³n de Letras
```python
# Extraer letras de las 8,000 canciones verificadas
python lyrics_extractor/genius_lyrics_extractor.py --input data/final_data/picked_data_1.csv
```

### Para Recomendaciones
```python
# Sistema de recomendaciÃ³n con datos hÃ­bridos
jupyter notebook pred.ipynb
```

## ğŸ“ˆ MÃ©tricas de Calidad

### ValidaciÃ³n Esperada
- **Quality Score**: â‰¥ 85/100
- **Distributional Similarity**: KS-test p-value > 0.05
- **Feature Coverage**: 95%+ del espacio original
- **Lyrics Availability**: 80% Â± 2%

### Archivos de ValidaciÃ³n
Los reportes de calidad se generan en:
```
outputs/selection_pipeline_[TIMESTAMP]/
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ selection_validation_report.md
â”‚   â””â”€â”€ quality_metrics.json
â””â”€â”€ reports/
    â””â”€â”€ final_selection_report.md
```

## ğŸ”„ Versionado

- **v0**: `picked_data_0.csv` - SelecciÃ³n manual/tradicional
- **v1**: `picked_data_1.csv` - Pipeline hÃ­brido con letras â† **ACTUAL**

## ğŸ“ InformaciÃ³n TÃ©cnica

- **Generado por**: Exploratory Analysis Selection Pipeline v1.0
- **Fecha**: 2025-01-28
- **Algoritmo**: Hybrid Multi-Stage Selection with Lyrics Verification
- **API utilizada**: Genius.com para verificaciÃ³n de letras

---

*Datasets optimizados para el Sistema de RecomendaciÃ³n Musical Multimodal*