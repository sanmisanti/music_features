#!/usr/bin/env python3
"""
AnÃ¡lisis profundo del dataset picked_data_lyrics.csv enfocado en caracterÃ­sticas musicales
para la implementaciÃ³n de clustering.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
from scipy import stats

warnings.filterwarnings('ignore')

# CaracterÃ­sticas musicales para clustering (sin time_signature segÃºn el README original)
MUSICAL_FEATURES = [
    'danceability', 'energy', 'key', 'loudness', 'mode',
    'speechiness', 'acousticness', 'instrumentalness', 
    'liveness', 'valence', 'tempo', 'duration_ms'
]

def load_dataset():
    """Cargar el dataset con letras."""
    dataset_path = Path("data/final_data/picked_data_lyrics.csv")
    
    print("ğŸ” Cargando dataset...")
    df = pd.read_csv(dataset_path, sep='^', encoding='utf-8')
    print(f"âœ… Dataset cargado: {df.shape[0]:,} canciones Ã— {df.shape[1]} columnas")
    print(f"ğŸ’¾ TamaÃ±o en memoria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
    
    return df

def analyze_dataset_structure(df):
    """Analizar estructura general del dataset."""
    print("\n" + "="*60)
    print("ğŸ“Š ANÃLISIS DE ESTRUCTURA DEL DATASET")
    print("="*60)
    
    print(f"ğŸ”¢ Dimensiones totales: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
    print(f"ğŸµ Canciones con letras: {df['lyrics'].notna().sum():,}")
    print(f"ğŸ“ Cobertura de letras: {df['lyrics'].notna().sum() / len(df) * 100:.1f}%")
    
    print(f"\nğŸ“‹ Columnas disponibles ({len(df.columns)}):")
    for i, col in enumerate(df.columns, 1):
        dtype_str = str(df[col].dtype)
        null_count = df[col].isnull().sum()
        print(f"{i:2d}. {col:25s} | {dtype_str:10s} | {null_count:4d} nulos")

def analyze_musical_features(df):
    """Analizar caracterÃ­sticas musicales especÃ­ficas."""
    print("\n" + "="*60)
    print("ğŸ¼ ANÃLISIS DE CARACTERÃSTICAS MUSICALES")
    print("="*60)
    
    # Verificar disponibilidad de features
    available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
    missing_features = [f for f in MUSICAL_FEATURES if f not in df.columns]
    
    print(f"âœ… Features disponibles: {len(available_features)}/{len(MUSICAL_FEATURES)}")
    print(f"ğŸ¯ Features para clustering: {available_features}")
    
    if missing_features:
        print(f"âŒ Features faltantes: {missing_features}")
    
    # AnÃ¡lisis estadÃ­stico por feature
    print(f"\nğŸ“Š ESTADÃSTICAS DESCRIPTIVAS:")
    print("-" * 80)
    
    musical_df = df[available_features]
    stats_df = musical_df.describe()
    
    for feature in available_features:
        data = df[feature]
        null_count = data.isnull().sum()
        null_pct = null_count / len(df) * 100
        
        print(f"\nğŸµ {feature.upper()}")
        print(f"   Tipo: {data.dtype}")
        print(f"   Nulos: {null_count} ({null_pct:.1f}%)")
        print(f"   Rango: [{data.min():.3f}, {data.max():.3f}]")
        print(f"   Media: {data.mean():.3f} Â± {data.std():.3f}")
        print(f"   Mediana: {data.median():.3f}")
        
        # Detectar outliers usando IQR
        Q1 = data.quantile(0.25)
        Q3 = data.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = ((data < lower_bound) | (data > upper_bound)).sum()
        outlier_pct = outliers / len(data) * 100
        
        print(f"   Outliers: {outliers} ({outlier_pct:.1f}%)")

def analyze_feature_distributions(df):
    """Analizar distribuciones de caracterÃ­sticas musicales."""
    print("\n" + "="*60)
    print("ğŸ“ˆ ANÃLISIS DE DISTRIBUCIONES")
    print("="*60)
    
    available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
    
    for feature in available_features:
        data = df[feature].dropna()
        
        # Test de normalidad
        if len(data) > 5000:
            # Para datasets grandes, usar muestra
            sample_data = data.sample(5000, random_state=42)
        else:
            sample_data = data
            
        shapiro_stat, shapiro_p = stats.shapiro(sample_data)
        is_normal = shapiro_p > 0.05
        
        # Skewness y Kurtosis
        skewness = stats.skew(data)
        kurtosis = stats.kurtosis(data)
        
        print(f"\nğŸµ {feature.upper()}:")
        print(f"   Normalidad: {'âœ… Normal' if is_normal else 'âŒ No normal'} (p={shapiro_p:.3f})")
        print(f"   AsimetrÃ­a: {skewness:.3f} ({'SimÃ©trica' if abs(skewness) < 0.5 else 'AsimÃ©trica'})")
        print(f"   Curtosis: {kurtosis:.3f}")

def analyze_feature_correlations(df):
    """Analizar correlaciones entre caracterÃ­sticas musicales."""
    print("\n" + "="*60)
    print("ğŸ”— ANÃLISIS DE CORRELACIONES")
    print("="*60)
    
    available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
    musical_df = df[available_features]
    
    # Calcular matriz de correlaciÃ³n
    corr_matrix = musical_df.corr()
    
    # Encontrar correlaciones altas
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.5:  # Umbral de correlaciÃ³n alta
                high_corr_pairs.append((
                    corr_matrix.columns[i], 
                    corr_matrix.columns[j], 
                    corr_val
                ))
    
    print(f"ğŸ” Correlaciones altas encontradas (|r| > 0.5): {len(high_corr_pairs)}")
    
    if high_corr_pairs:
        print("\nğŸ“Š CORRELACIONES SIGNIFICATIVAS:")
        print("-" * 50)
        for feat1, feat2, corr_val in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):
            direction = "positiva" if corr_val > 0 else "negativa"
            strength = "muy fuerte" if abs(corr_val) > 0.8 else "fuerte" if abs(corr_val) > 0.6 else "moderada"
            print(f"   {feat1:15s} â†” {feat2:15s}: {corr_val:6.3f} ({strength} {direction})")
    else:
        print("âœ… No hay correlaciones altas entre features (bueno para clustering)")

def check_data_quality(df):
    """Verificar calidad de los datos musicales."""
    print("\n" + "="*60)
    print("ğŸ” ANÃLISIS DE CALIDAD DE DATOS")
    print("="*60)
    
    available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
    
    # Rangos vÃ¡lidos para caracterÃ­sticas de Spotify
    feature_ranges = {
        'danceability': (0, 1),
        'energy': (0, 1),
        'speechiness': (0, 1),
        'acousticness': (0, 1),
        'instrumentalness': (0, 1),
        'liveness': (0, 1),
        'valence': (0, 1),
        'key': (0, 11),
        'mode': (0, 1),
        'tempo': (30, 300),
        'loudness': (-80, 10),
        'duration_ms': (10000, 1800000),  # 10 seg a 30 min
    }
    
    quality_issues = []
    
    for feature in available_features:
        if feature in feature_ranges:
            min_val, max_val = feature_ranges[feature]
            data = df[feature]
            
            # Valores fuera de rango
            out_of_range = ((data < min_val) | (data > max_val)).sum()
            if out_of_range > 0:
                quality_issues.append(f"{feature}: {out_of_range} valores fuera de rango [{min_val}, {max_val}]")
            
            # Valores nulos
            null_count = data.isnull().sum()
            if null_count > 0:
                quality_issues.append(f"{feature}: {null_count} valores nulos")
    
    if quality_issues:
        print("âš ï¸  PROBLEMAS DE CALIDAD ENCONTRADOS:")
        for issue in quality_issues:
            print(f"   ğŸ”¸ {issue}")
    else:
        print("âœ… Datos de alta calidad: sin valores fuera de rango ni nulos")

def analyze_genre_distribution(df):
    """Analizar distribuciÃ³n por gÃ©neros."""
    print("\n" + "="*60)
    print("ğŸ­ ANÃLISIS POR GÃ‰NEROS")
    print("="*60)
    
    if 'playlist_genre' in df.columns:
        genre_counts = df['playlist_genre'].value_counts()
        print(f"ğŸµ GÃ©neros Ãºnicos: {len(genre_counts)}")
        print(f"ğŸ“Š DistribuciÃ³n de gÃ©neros (top 10):")
        print("-" * 40)
        
        for genre, count in genre_counts.head(10).items():
            percentage = count / len(df) * 100
            print(f"   {genre:20s}: {count:4d} ({percentage:5.1f}%)")
        
        # AnÃ¡lisis de caracterÃ­sticas por gÃ©nero (top 5)
        print(f"\nğŸ¼ CARACTERÃSTICAS PROMEDIO POR GÃ‰NERO:")
        print("-" * 60)
        
        top_genres = genre_counts.head(5).index
        available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
        
        for genre in top_genres:
            genre_data = df[df['playlist_genre'] == genre]
            print(f"\nğŸµ {genre.upper()} ({len(genre_data)} canciones):")
            
            for feature in available_features[:6]:  # Mostrar solo 6 features principales
                avg_val = genre_data[feature].mean()
                std_val = genre_data[feature].std()
                print(f"   {feature:15s}: {avg_val:.3f} Â± {std_val:.3f}")

def generate_clustering_recommendations(df):
    """Generar recomendaciones para clustering."""
    print("\n" + "="*60)
    print("ğŸ¯ RECOMENDACIONES PARA CLUSTERING")
    print("="*60)
    
    available_features = [f for f in MUSICAL_FEATURES if f in df.columns]
    musical_df = df[available_features]
    
    print(f"ğŸ“Š CONFIGURACIÃ“N RECOMENDADA:")
    print(f"   ğŸµ Dataset: {len(df):,} canciones")
    print(f"   ğŸ”§ Features: {len(available_features)} caracterÃ­sticas musicales")
    print(f"   ğŸ“ NormalizaciÃ³n: StandardScaler (requerida)")
    print(f"   ğŸ¯ Algoritmo: K-Means con optimizaciÃ³n automÃ¡tica de K")
    
    # Estimar K Ã³ptimo basado en el tamaÃ±o del dataset
    # Regla empÃ­rica: K â‰ˆ sqrt(n/2) pero limitado a un rango prÃ¡ctico
    n = len(df)
    k_estimate = int(np.sqrt(n / 2))
    k_min = max(3, min(k_estimate - 2, 5))
    k_max = min(k_estimate + 3, 12)
    
    print(f"   ğŸ” Rango K recomendado: {k_min}-{k_max} (estimado: {k_estimate})")
    print(f"   âš¡ Algoritmo optimizado: MiniBatchKMeans para >5000 muestras")
    print(f"   ğŸ² Random state: 42 (reproducibilidad)")
    
    # Recomendaciones de PCA
    print(f"\nğŸ”¬ ANÃLISIS DIMENSIONAL:")
    print(f"   ğŸ“Š Dimensiones originales: {len(available_features)}D")
    print(f"   ğŸ”„ PCA recomendado: SÃ­ (experiencia previa exitosa)")
    print(f"   ğŸ“‰ Componentes sugeridos: 5-8 (balance calidad/interpretabilidad)")
    
    # MÃ©tricas de evaluaciÃ³n
    print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
    print(f"   ğŸ¯ Principal: Silhouette Score (objetivo: >0.314)")
    print(f"   ğŸ”— Adicional: Calinski-Harabasz Index")
    print(f"   ğŸ“Š Referencia: Davies-Bouldin Index (menor es mejor)")
    
    # Consideraciones especiales
    print(f"\nâš ï¸  CONSIDERACIONES ESPECIALES:")
    
    # Verificar si hay caracterÃ­sticas categÃ³ricas
    categorical_features = []
    for feature in available_features:
        unique_vals = df[feature].nunique()
        if unique_vals <= 12:  # Posiblemente categÃ³rica
            categorical_features.append(f"{feature} ({unique_vals} valores Ãºnicos)")
    
    if categorical_features:
        print(f"   ğŸ”¸ Features categÃ³ricas detectadas:")
        for cat_feat in categorical_features:
            print(f"     - {cat_feat}")
    
    # Verificar distribuciÃ³n de gÃ©neros
    if 'playlist_genre' in df.columns:
        genre_count = df['playlist_genre'].nunique()
        print(f"   ğŸ­ GÃ©neros disponibles: {genre_count} (usar para validaciÃ³n)")
    
    print(f"\nâœ… PASOS SIGUIENTES:")
    print(f"   1. Implementar carga con separador '^'")
    print(f"   2. Aplicar StandardScaler a features musicales")
    print(f"   3. Probar clustering con y sin PCA")
    print(f"   4. Comparar con modelos baseline existentes")
    print(f"   5. Validar clusters usando gÃ©neros como referencia")

def main():
    """FunciÃ³n principal del anÃ¡lisis."""
    print("ğŸµ ANÃLISIS PROFUNDO DEL DATASET PARA CLUSTERING MUSICAL")
    print("=" * 70)
    
    try:
        # Cargar dataset
        df = load_dataset()
        
        # Realizar anÃ¡lisis
        analyze_dataset_structure(df)
        analyze_musical_features(df)
        analyze_feature_distributions(df)
        analyze_feature_correlations(df)
        check_data_quality(df)
        analyze_genre_distribution(df)
        generate_clustering_recommendations(df)
        
        print(f"\nğŸ‰ ANÃLISIS COMPLETADO EXITOSAMENTE")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ Error durante el anÃ¡lisis: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())