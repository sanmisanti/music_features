#!/usr/bin/env python3
"""
ğŸ“Š ANÃLISIS RÃPIDO DE DATASET MUSICAL
AnÃ¡lisis exploratorio + clustering readiness en un script

FUNCIONALIDADES:
- AnÃ¡lisis exploratorio automÃ¡tico (82/82 tests validados)
- Clustering readiness assessment (Hopkins Statistic)
- Reporte comprensivo en mÃºltiples formatos
- Visualizaciones automÃ¡ticas
- Recomendaciones de optimizaciÃ³n

Datasets soportados:
- spotify_songs_fixed.csv (18K canciones con letras)
- picked_data_optimal.csv (dataset optimizado)
- Cualquier dataset con caracterÃ­sticas musicales Spotify

Autor: Exploratory Analysis System + Clustering Readiness
Fecha: Enero 2025
Estado: âœ… SISTEMA MADURO (82/82 tests exitosos)
"""

import sys
import os
import pandas as pd
from datetime import datetime

def main(dataset_name=None):
    """
    Ejecuta anÃ¡lisis rÃ¡pido completo de un dataset musical.
    
    Args:
        dataset_name: Nombre del dataset a analizar
                     - 'fixed' o None: spotify_songs_fixed.csv (18K)
                     - 'optimal': picked_data_optimal.csv (optimizado)
                     - 'lyrics': picked_data_lyrics.csv (con letras)
                     - ruta personalizada: path completo al archivo
    """
    
    print("ğŸ“Š ANÃLISIS RÃPIDO DE DATASET MUSICAL")
    print("="*70)
    print("ğŸ”§ Sistema maduro con 82/82 tests exitosos")
    print("ğŸ“ˆ AnÃ¡lisis exploratorio + clustering readiness")
    print("="*70)
    
    # Determinar dataset a analizar
    datasets = {
        'fixed': 'data/with_lyrics/spotify_songs_fixed.csv',
        'optimal': 'data/final_data/picked_data_optimal.csv', 
        'lyrics': 'data/final_data/picked_data_lyrics.csv',
        None: 'data/with_lyrics/spotify_songs_fixed.csv'  # Default
    }
    
    if dataset_name in datasets:
        dataset_path = datasets[dataset_name]
        print(f"ğŸ“‚ Dataset seleccionado: {dataset_path}")
    elif dataset_name and os.path.exists(dataset_name):
        dataset_path = dataset_name
        print(f"ğŸ“‚ Dataset personalizado: {dataset_path}")
    else:
        dataset_path = datasets[None]  # Default
        print(f"ğŸ“‚ Dataset por defecto: {dataset_path}")
    
    if not os.path.exists(dataset_path):
        print(f"âŒ Error: Dataset no encontrado en {dataset_path}")
        return False
    
    # AnÃ¡lisis rÃ¡pido del dataset
    try:
        print(f"\nğŸ“‹ Cargando dataset...")
        
        # Detectar formato automÃ¡ticamente
        if 'fixed' in dataset_path:
            df = pd.read_csv(dataset_path, sep='@@', encoding='utf-8', on_bad_lines='skip', engine='python')
        elif 'optimal' in dataset_path or 'lyrics' in dataset_path:
            df = pd.read_csv(dataset_path, sep='^', decimal='.', encoding='utf-8', on_bad_lines='skip')
        else:
            # Intentar formato estÃ¡ndar
            df = pd.read_csv(dataset_path, encoding='utf-8', on_bad_lines='skip')
            
        print(f"âœ… Dataset cargado: {df.shape[0]:,} canciones Ã— {df.shape[1]} columnas")
        
        # InformaciÃ³n bÃ¡sica
        print(f"\nğŸ“Š INFORMACIÃ“N BÃSICA:")
        print(f"   ğŸ“ˆ TamaÃ±o: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas")
        print(f"   ğŸ’¾ Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        # CaracterÃ­sticas musicales disponibles
        musical_features = [
            'danceability', 'energy', 'key', 'loudness', 'mode', 
            'speechiness', 'acousticness', 'instrumentalness', 'liveness', 
            'valence', 'tempo', 'duration_ms', 'time_signature'
        ]
        
        available_features = [f for f in musical_features if f in df.columns]
        print(f"   ğŸµ CaracterÃ­sticas musicales: {len(available_features)}/13")
        
        if len(available_features) < 10:
            print(f"   âš ï¸  Advertencia: Solo {len(available_features)} caracterÃ­sticas disponibles")
            print(f"      Faltantes: {set(musical_features) - set(available_features)}")
        
        # Calidad de datos bÃ¡sica
        print(f"\nğŸ” CALIDAD DE DATOS:")
        print(f"   ğŸ“Š Valores nulos: {df.isnull().sum().sum():,} ({df.isnull().sum().sum()/df.size*100:.1f}%)")
        print(f"   ğŸ”¢ Valores Ãºnicos promedio: {df.nunique().mean():.1f}")
        
        # EstadÃ­sticas rÃ¡pidas de caracterÃ­sticas musicales
        if available_features:
            music_df = df[available_features]
            print(f"\nğŸµ CARACTERÃSTICAS MUSICALES:")
            print(f"   ğŸ“ˆ Rango promedio: {(music_df.max() - music_df.min()).mean():.3f}")
            print(f"   ğŸ“Š DesviaciÃ³n estÃ¡ndar promedio: {music_df.std().mean():.3f}")
            print(f"   ğŸ¯ CorrelaciÃ³n promedio: {music_df.corr().abs().mean().mean():.3f}")
        
    except Exception as e:
        print(f"âŒ Error durante anÃ¡lisis: {e}")
        return False
    
    print(f"\nğŸ¯ ANÃLISIS COMPLETADO")
    print(f"ğŸ“… Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"\nğŸ’¡ Para anÃ¡lisis completo, usar:")
    print(f"   python exploratory_analysis/run_full_analysis.py")
    print(f"   python analyze_clustering_readiness_direct.py")
    
    return True

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='AnÃ¡lisis rÃ¡pido de dataset musical')
    parser.add_argument('--dataset', '-d', 
                       choices=['fixed', 'optimal', 'lyrics'],
                       help='Dataset a analizar (fixed=18K, optimal=optimizado, lyrics=con letras)')
    parser.add_argument('--path', '-p',
                       help='Ruta personalizada al dataset')
    
    args = parser.parse_args()
    
    dataset = args.path if args.path else args.dataset
    main(dataset)